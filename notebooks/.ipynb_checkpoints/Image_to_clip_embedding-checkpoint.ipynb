{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photo to CLIP Embedding Converter\n",
    "\n",
    "This notebook allows you to select images from a folder and convert them to CLIP embeddings.\n",
    "The embeddings are saved as JSON files for use in your Flux pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install torch torchvision transformers pillow ipywidgets --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import json\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "current_dir = Path(os.getcwd())\n",
    "output_dir = current_dir.parent / \"data\" / \"embeddings\" / \"CLIP\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Current directory: {current_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP model\n",
    "print(\"Loading CLIP model...\")\n",
    "model_name = \"openai/clip-vit-large-patch14\"\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_files(directory):\n",
    "    \"\"\"Get all image files from a directory\"\"\"\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}\n",
    "    directory = Path(directory)\n",
    "    \n",
    "    if not directory.exists():\n",
    "        return []\n",
    "    \n",
    "    image_files = []\n",
    "    for file in directory.iterdir():\n",
    "        if file.is_file() and file.suffix.lower() in image_extensions:\n",
    "            image_files.append(file)\n",
    "    \n",
    "    return sorted(image_files)\n",
    "\n",
    "\n",
    "def extract_clip_image_embedding(image_path, return_tokens=True):\n",
    "    \"\"\"\n",
    "    Extract CLIP image embeddings from an image file.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        return_tokens: If True, return token embeddings [257, 768].\n",
    "                       If False, return pooled embedding [768]\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with embedding data\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Process the image\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Get image embeddings\n",
    "    with torch.no_grad():\n",
    "        if return_tokens:\n",
    "            # Get full token embeddings\n",
    "            vision_outputs = model.vision_model(**inputs)\n",
    "            image_embeds = vision_outputs.last_hidden_state  # [1, 257, 768]\n",
    "            image_embeds = image_embeds.squeeze(0)  # [257, 768]\n",
    "            shape = list(image_embeds.shape)\n",
    "        else:\n",
    "            # Get pooled embedding\n",
    "            image_features = model.get_image_features(**inputs)  # [1, 768]\n",
    "            # Normalize\n",
    "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "            image_embeds = image_features.squeeze(0)  # [768]\n",
    "            shape = list(image_embeds.shape)\n",
    "    \n",
    "    # Convert to list for JSON serialization\n",
    "    embedding_list = image_embeds.cpu().numpy().tolist()\n",
    "    \n",
    "    return {\n",
    "        \"source_image\": str(image_path.name),\n",
    "        \"embedding\": embedding_list,\n",
    "        \"shape\": shape,\n",
    "        \"type\": \"clip_image_tokens\" if return_tokens else \"clip_image_pooled\",\n",
    "        \"model\": model_name\n",
    "    }\n",
    "\n",
    "\n",
    "def save_embedding_json(embedding_data, output_path):\n",
    "    \"\"\"Save embedding data to JSON file\"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(embedding_data, f)\n",
    "    print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widget for selecting image directory\n",
    "image_dir_input = widgets.Text(\n",
    "    value=str(current_dir / \"example_photos\"),\n",
    "    placeholder='Enter path to image folder',\n",
    "    description='Image Folder:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='600px')\n",
    ")\n",
    "\n",
    "load_button = widgets.Button(\n",
    "    description='Load Images',\n",
    "    button_style='info',\n",
    "    tooltip='Load images from the specified folder'\n",
    ")\n",
    "\n",
    "image_selector = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description='Select Image:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='600px'),\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "embedding_type = widgets.RadioButtons(\n",
    "    options=[\n",
    "        ('Token embeddings [257, 768] - Full detail', True),\n",
    "        ('Pooled embedding [768] - Single vector', False)\n",
    "    ],\n",
    "    description='Embedding Type:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "preview_image = widgets.Image(\n",
    "    format='png',\n",
    "    width=400,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "convert_button = widgets.Button(\n",
    "    description='Convert to CLIP Embedding',\n",
    "    button_style='success',\n",
    "    tooltip='Extract CLIP embedding and save as JSON',\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "output_text = widgets.Output()\n",
    "\n",
    "# Current state\n",
    "state = {\n",
    "    'image_files': [],\n",
    "    'current_image': None\n",
    "}\n",
    "\n",
    "\n",
    "def on_load_images(b):\n",
    "    \"\"\"Load images from the specified directory\"\"\"\n",
    "    with output_text:\n",
    "        clear_output()\n",
    "        image_dir = Path(image_dir_input.value)\n",
    "        \n",
    "        if not image_dir.exists():\n",
    "            print(f\"‚ùå Directory not found: {image_dir}\")\n",
    "            image_selector.options = []\n",
    "            image_selector.disabled = True\n",
    "            convert_button.disabled = True\n",
    "            return\n",
    "        \n",
    "        image_files = get_image_files(image_dir)\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"‚ùå No images found in: {image_dir}\")\n",
    "            image_selector.options = []\n",
    "            image_selector.disabled = True\n",
    "            convert_button.disabled = True\n",
    "            return\n",
    "        \n",
    "        state['image_files'] = image_files\n",
    "        image_selector.options = [(f.name, f) for f in image_files]\n",
    "        image_selector.disabled = False\n",
    "        convert_button.disabled = False\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {len(image_files)} images from {image_dir}\")\n",
    "\n",
    "\n",
    "def on_image_selected(change):\n",
    "    \"\"\"Update preview when image is selected\"\"\"\n",
    "    if change['new'] is None:\n",
    "        return\n",
    "    \n",
    "    image_path = change['new']\n",
    "    state['current_image'] = image_path\n",
    "    \n",
    "    # Load and display preview\n",
    "    with open(image_path, 'rb') as f:\n",
    "        preview_image.value = f.read()\n",
    "    \n",
    "    with output_text:\n",
    "        print(f\"Selected: {image_path.name}\")\n",
    "\n",
    "\n",
    "def on_convert(b):\n",
    "    \"\"\"Convert selected image to CLIP embedding\"\"\"\n",
    "    with output_text:\n",
    "        clear_output()\n",
    "        \n",
    "        if state['current_image'] is None:\n",
    "            print(\"‚ùå No image selected\")\n",
    "            return\n",
    "        \n",
    "        image_path = state['current_image']\n",
    "        return_tokens = embedding_type.value\n",
    "        \n",
    "        print(f\"üîÑ Processing: {image_path.name}\")\n",
    "        print(f\"   Type: {'Token embeddings [257, 768]' if return_tokens else 'Pooled embedding [768]'}\")\n",
    "        \n",
    "        try:\n",
    "            # Extract embedding\n",
    "            embedding_data = extract_clip_image_embedding(image_path, return_tokens)\n",
    "            \n",
    "            # Generate output filename\n",
    "            input_stem = image_path.stem  # filename without extension\n",
    "            output_filename = f\"{input_stem}_from_image.json\"\n",
    "            output_path = output_dir / output_filename\n",
    "            \n",
    "            # Save to JSON\n",
    "            save_embedding_json(embedding_data, output_path)\n",
    "            \n",
    "            print(f\"‚úÖ Success!\")\n",
    "            print(f\"   Shape: {embedding_data['shape']}\")\n",
    "            print(f\"   Saved to: {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "\n",
    "# Connect callbacks\n",
    "load_button.on_click(on_load_images)\n",
    "image_selector.observe(on_image_selected, names='value')\n",
    "convert_button.on_click(on_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the interface\n",
    "print(\"=\" * 70)\n",
    "print(\"Photo to CLIP Embedding Converter\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        widgets.HBox([image_dir_input, load_button]),\n",
    "        image_selector,\n",
    "        preview_image,\n",
    "        embedding_type,\n",
    "        convert_button,\n",
    "        output_text\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "\n",
    "1. **Specify Image Folder**: Enter the path to your folder containing example photos\n",
    "2. **Load Images**: Click \"Load Images\" to scan the folder\n",
    "3. **Select Image**: Choose an image from the dropdown menu\n",
    "4. **Choose Embedding Type**:\n",
    "   - **Token embeddings [257, 768]**: Full token-level embeddings (like your text CLIP with 77 tokens)\n",
    "   - **Pooled embedding [768]**: Single vector representation\n",
    "5. **Convert**: Click \"Convert to CLIP Embedding\" to process and save\n",
    "\n",
    "The output JSON files will be saved in: `../data/embeddings/CLIP/`\n",
    "\n",
    "Filename format: `{original_image_name}_from_image.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Load and Use the Embedding\n",
    "\n",
    "After converting images, you can load and use the embeddings in your Flux pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load a saved embedding\n",
    "def load_embedding(json_path):\n",
    "    \"\"\"Load embedding from JSON file\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    embedding = torch.tensor(data['embedding'])\n",
    "    print(f\"Loaded: {data['source_image']}\")\n",
    "    print(f\"Type: {data['type']}\")\n",
    "    print(f\"Shape: {data['shape']}\")\n",
    "    print(f\"Model: {data['model']}\")\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "# Uncomment to test loading:\n",
    "# embedding = load_embedding(output_dir / \"your_image_from_image.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- **Token Embeddings vs Pooled**: \n",
    "  - Token embeddings preserve spatial/patch information (good for detailed control)\n",
    "  - Pooled embeddings are more compact (good for overall style/content)\n",
    "  \n",
    "- **Compatibility**: The embeddings use the same CLIP model (`clip-vit-large-patch14`) for consistency\n",
    "\n",
    "- **File Size**: Token embeddings (~1.5 MB) are larger than pooled embeddings (~6 KB)\n",
    "\n",
    "- **Integration**: You can blend these image embeddings with text embeddings or use them directly in your Flux pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
