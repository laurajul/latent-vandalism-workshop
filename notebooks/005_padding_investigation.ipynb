{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Understanding Padding Tokens in CLIP Embeddings\n",
    "\n",
    "## The Question\n",
    "\n",
    "When we have a prompt like **\"a beaver with blue teeth\"**, it only uses maybe 10 tokens out of 77 total positions. The remaining 67 positions are **padding tokens**.\n",
    "\n",
    "**Key Questions:**\n",
    "1. Are padding tokens always the same?\n",
    "2. How do they affect the final embedding?\n",
    "3. Do padding embeddings at position 10 differ from padding at position 50?\n",
    "4. Can we manipulate padding tokens to affect Flux output?\n",
    "\n",
    "Let's investigate!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load CLIP text model\n",
    "model_name = \"openai/clip-vit-large-patch14\"\n",
    "tokenizer = CLIPTokenizer.from_pretrained(model_name)\n",
    "model = CLIPTextModel.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"âœ“ Model loaded\")\n",
    "print(f\"  Vocab size: {tokenizer.vocab_size}\")\n",
    "print(f\"  Max length: {tokenizer.model_max_length}\")\n",
    "print(f\"  Pad token: '{tokenizer.pad_token}' (ID: {tokenizer.pad_token_id})\")\n",
    "print(f\"  EOS token: '{tokenizer.eos_token}' (ID: {tokenizer.eos_token_id})\")\n",
    "print(f\"  BOS token: '{tokenizer.bos_token}' (ID: {tokenizer.bos_token_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "investigate-tokens",
   "metadata": {},
   "source": [
    "## Investigation 1: What Are the Token IDs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "investigate-tokens-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a short prompt\n",
    "prompt = \"a beaver with blue teeth\"\n",
    "\n",
    "# Tokenize\n",
    "tokens = tokenizer(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=77,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "token_ids = tokens['input_ids'][0].tolist()\n",
    "attention_mask = tokens['attention_mask'][0].tolist()\n",
    "\n",
    "print(f\"Prompt: '{prompt}'\")\n",
    "print(f\"\\nToken IDs (first 15 positions):\")\n",
    "print(\"Position | Token ID | Attention | Decoded\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(15):\n",
    "    decoded = tokenizer.decode([token_ids[i]])\n",
    "    print(f\"{i:8} | {token_ids[i]:8} | {attention_mask[i]:9} | '{decoded}'\")\n",
    "\n",
    "print(\"\\n...\")\n",
    "print(\"\\nLast 5 positions:\")\n",
    "for i in range(72, 77):\n",
    "    decoded = tokenizer.decode([token_ids[i]])\n",
    "    print(f\"{i:8} | {token_ids[i]:8} | {attention_mask[i]:9} | '{decoded}'\")\n",
    "\n",
    "# Count real tokens vs padding\n",
    "num_real_tokens = sum(attention_mask)\n",
    "num_padding = 77 - num_real_tokens\n",
    "print(f\"\\nâœ“ Real tokens: {num_real_tokens}\")\n",
    "print(f\"âœ“ Padding tokens: {num_padding}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "investigate-embeddings",
   "metadata": {},
   "source": [
    "## Investigation 2: Are Padding Embeddings Identical?\n",
    "\n",
    "Let's check if padding embeddings at different positions are the same or different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "investigate-embeddings-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embedding\n",
    "with torch.no_grad():\n",
    "    tokens_device = {k: v.to(device) for k, v in tokens.items()}\n",
    "    outputs = model(**tokens_device)\n",
    "    embedding = outputs.last_hidden_state[0]  # [77, 768]\n",
    "\n",
    "embedding_np = embedding.cpu().numpy()\n",
    "\n",
    "print(f\"Embedding shape: {embedding_np.shape}\")\n",
    "print(f\"\\nLet's compare padding embeddings at different positions...\\n\")\n",
    "\n",
    "# Find first padding position\n",
    "first_padding_pos = num_real_tokens\n",
    "print(f\"First padding position: {first_padding_pos}\")\n",
    "\n",
    "# Compare padding embeddings at different positions\n",
    "if num_padding > 1:\n",
    "    padding_positions = [first_padding_pos, first_padding_pos + 10, first_padding_pos + 20, 76]\n",
    "    padding_positions = [p for p in padding_positions if p < 77]\n",
    "    \n",
    "    print(f\"\\nComparing padding embeddings at positions: {padding_positions}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, pos in enumerate(padding_positions):\n",
    "        emb = embedding_np[pos]\n",
    "        print(f\"\\nPosition {pos}:\")\n",
    "        print(f\"  First 10 values: {emb[:10]}\")\n",
    "        print(f\"  Mean: {emb.mean():.6f}\")\n",
    "        print(f\"  Std: {emb.std():.6f}\")\n",
    "        print(f\"  L2 norm: {np.linalg.norm(emb):.6f}\")\n",
    "    \n",
    "    # Calculate pairwise differences\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Pairwise Cosine Similarities Between Padding Embeddings:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i in range(len(padding_positions)):\n",
    "        for j in range(i+1, len(padding_positions)):\n",
    "            pos_i = padding_positions[i]\n",
    "            pos_j = padding_positions[j]\n",
    "            emb_i = embedding_np[pos_i]\n",
    "            emb_j = embedding_np[pos_j]\n",
    "            \n",
    "            # Cosine similarity\n",
    "            cos_sim = np.dot(emb_i, emb_j) / (np.linalg.norm(emb_i) * np.linalg.norm(emb_j))\n",
    "            \n",
    "            # L2 distance\n",
    "            l2_dist = np.linalg.norm(emb_i - emb_j)\n",
    "            \n",
    "            print(f\"Positions {pos_i} vs {pos_j}:\")\n",
    "            print(f\"  Cosine similarity: {cos_sim:.8f}\")\n",
    "            print(f\"  L2 distance: {l2_dist:.6f}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-prompts",
   "metadata": {},
   "source": [
    "## Investigation 3: Are Padding Embeddings the Same Across Different Prompts?\n",
    "\n",
    "Do the padding embeddings change when we use different prompts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-prompts-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple prompts of different lengths\n",
    "test_prompts = [\n",
    "    \"cat\",\n",
    "    \"a red cat\",\n",
    "    \"a beaver with blue teeth\",\n",
    "    \"an elephant standing in a field of flowers\",\n",
    "]\n",
    "\n",
    "padding_embeddings = {}\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    # Tokenize\n",
    "    tokens = tokenizer(\n",
    "        prompt,\n",
    "        padding=\"max_length\",\n",
    "        max_length=77,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Get embedding\n",
    "    with torch.no_grad():\n",
    "        tokens_device = {k: v.to(device) for k, v in tokens.items()}\n",
    "        outputs = model(**tokens_device)\n",
    "        embedding = outputs.last_hidden_state[0].cpu().numpy()\n",
    "    \n",
    "    # Find padding positions\n",
    "    attention_mask = tokens['attention_mask'][0].tolist()\n",
    "    num_real = sum(attention_mask)\n",
    "    first_padding = num_real\n",
    "    \n",
    "    # Store padding embedding at a consistent position (e.g., position 50)\n",
    "    if first_padding < 50:\n",
    "        padding_embeddings[prompt] = {\n",
    "            'num_real_tokens': num_real,\n",
    "            'first_padding': first_padding,\n",
    "            'padding_at_50': embedding[50],\n",
    "            'padding_at_76': embedding[76]\n",
    "        }\n",
    "    \n",
    "    print(f\"Prompt: '{prompt}'\")\n",
    "    print(f\"  Real tokens: {num_real}\")\n",
    "    print(f\"  First padding position: {first_padding}\")\n",
    "    print()\n",
    "\n",
    "# Compare padding embeddings across prompts\n",
    "print(\"=\"*60)\n",
    "print(\"Comparing Padding at Position 50 Across Different Prompts:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "prompts_list = list(padding_embeddings.keys())\n",
    "for i in range(len(prompts_list)):\n",
    "    for j in range(i+1, len(prompts_list)):\n",
    "        prompt_i = prompts_list[i]\n",
    "        prompt_j = prompts_list[j]\n",
    "        \n",
    "        emb_i = padding_embeddings[prompt_i]['padding_at_50']\n",
    "        emb_j = padding_embeddings[prompt_j]['padding_at_50']\n",
    "        \n",
    "        cos_sim = np.dot(emb_i, emb_j) / (np.linalg.norm(emb_i) * np.linalg.norm(emb_j))\n",
    "        l2_dist = np.linalg.norm(emb_i - emb_j)\n",
    "        \n",
    "        print(f\"\\n'{prompt_i[:30]}...' vs '{prompt_j[:30]}...'\")\n",
    "        print(f\"  Cosine similarity: {cos_sim:.10f}\")\n",
    "        print(f\"  L2 distance: {l2_dist:.10f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if cos_sim > 0.9999:\n",
    "    print(\"âœ“ CONCLUSION: Padding embeddings at the same position are\")\n",
    "    print(\"  NEARLY IDENTICAL across different prompts!\")\n",
    "else:\n",
    "    print(\"âœ“ CONCLUSION: Padding embeddings differ across prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize",
   "metadata": {},
   "source": [
    "## Visualization: Real Tokens vs Padding Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"a beaver with blue teeth\" prompt\n",
    "prompt = \"a beaver with blue teeth\"\n",
    "\n",
    "tokens = tokenizer(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=77,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens_device = {k: v.to(device) for k, v in tokens.items()}\n",
    "    outputs = model(**tokens_device)\n",
    "    embedding = outputs.last_hidden_state[0].cpu().numpy()\n",
    "\n",
    "attention_mask = tokens['attention_mask'][0].tolist()\n",
    "num_real = sum(attention_mask)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Heatmap of embedding\n",
    "ax1 = axes[0]\n",
    "im = ax1.imshow(embedding.T, aspect='auto', cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "ax1.axvline(x=num_real-0.5, color='lime', linewidth=3, label='Padding starts here')\n",
    "ax1.set_xlabel('Token Position', fontsize=12)\n",
    "ax1.set_ylabel('Embedding Dimension', fontsize=12)\n",
    "ax1.set_title(f'CLIP Text Embedding: \"{prompt}\"\\n(Green line = where padding starts)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "plt.colorbar(im, ax=ax1, label='Embedding Value')\n",
    "\n",
    "# Plot 2: L2 norms of each token embedding\n",
    "ax2 = axes[1]\n",
    "norms = [np.linalg.norm(embedding[i]) for i in range(77)]\n",
    "colors = ['steelblue' if i < num_real else 'orange' for i in range(77)]\n",
    "ax2.bar(range(77), norms, color=colors, alpha=0.7)\n",
    "ax2.axvline(x=num_real-0.5, color='lime', linewidth=3, linestyle='--', \n",
    "            label='Padding starts here')\n",
    "ax2.set_xlabel('Token Position', fontsize=12)\n",
    "ax2.set_ylabel('L2 Norm', fontsize=12)\n",
    "ax2.set_title('L2 Norm of Each Token Embedding\\n(Blue = real tokens, Orange = padding)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ“ Visualization complete\")\n",
    "print(f\"  Real tokens: {num_real}\")\n",
    "print(f\"  Padding tokens: {77 - num_real}\")\n",
    "print(f\"  Average norm of real tokens: {np.mean(norms[:num_real]):.4f}\")\n",
    "print(f\"  Average norm of padding tokens: {np.mean(norms[num_real:]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experiment",
   "metadata": {},
   "source": [
    "## Experiment: What If We Zero Out Padding?\n",
    "\n",
    "What happens if we replace padding embeddings with zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experiment-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "prompt = \"a beaver with blue teeth\"\n",
    "\n",
    "# Generate normal embedding\n",
    "tokens = tokenizer(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=77,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens_device = {k: v.to(device) for k, v in tokens.items()}\n",
    "    outputs = model(**tokens_device)\n",
    "    embedding_normal = outputs.last_hidden_state[0].cpu().numpy()\n",
    "\n",
    "attention_mask = tokens['attention_mask'][0].tolist()\n",
    "num_real = sum(attention_mask)\n",
    "\n",
    "# Create version with zeroed padding\n",
    "embedding_zeroed = embedding_normal.copy()\n",
    "embedding_zeroed[num_real:] = 0  # Zero out all padding positions\n",
    "\n",
    "print(f\"Prompt: '{prompt}'\")\n",
    "print(f\"Real tokens: {num_real}\")\n",
    "print(f\"\\nOriginal embedding stats:\")\n",
    "print(f\"  Mean: {embedding_normal.mean():.6f}\")\n",
    "print(f\"  Std: {embedding_normal.std():.6f}\")\n",
    "print(f\"  Norm: {np.linalg.norm(embedding_normal):.6f}\")\n",
    "\n",
    "print(f\"\\nZeroed padding embedding stats:\")\n",
    "print(f\"  Mean: {embedding_zeroed.mean():.6f}\")\n",
    "print(f\"  Std: {embedding_zeroed.std():.6f}\")\n",
    "print(f\"  Norm: {np.linalg.norm(embedding_zeroed):.6f}\")\n",
    "\n",
    "# Visualize difference\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Original\n",
    "im1 = axes[0].imshow(embedding_normal.T, aspect='auto', cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "axes[0].axvline(x=num_real-0.5, color='lime', linewidth=2)\n",
    "axes[0].set_title('Original Embedding (with padding)', fontweight='bold')\n",
    "axes[0].set_ylabel('Dimension')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Zeroed\n",
    "im2 = axes[1].imshow(embedding_zeroed.T, aspect='auto', cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "axes[1].axvline(x=num_real-0.5, color='lime', linewidth=2)\n",
    "axes[1].set_title('Zeroed Padding Embedding', fontweight='bold')\n",
    "axes[1].set_ylabel('Dimension')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Difference\n",
    "diff = embedding_normal - embedding_zeroed\n",
    "im3 = axes[2].imshow(diff.T, aspect='auto', cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "axes[2].axvline(x=num_real-0.5, color='lime', linewidth=2)\n",
    "axes[2].set_title('Difference (what we removed)', fontweight='bold')\n",
    "axes[2].set_xlabel('Token Position')\n",
    "axes[2].set_ylabel('Dimension')\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save both versions\n",
    "current_dir = Path(os.getcwd())\n",
    "output_dir = current_dir.parent / \"data\" / \"embeddings\" / \"CLIP\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save normal\n",
    "normal_data = {\n",
    "    \"prompt\": prompt,\n",
    "    \"embedding\": embedding_normal.tolist(),\n",
    "    \"shape\": [77, 768]\n",
    "}\n",
    "with open(output_dir / \"beaver_normal.json\", 'w') as f:\n",
    "    json.dump(normal_data, f)\n",
    "\n",
    "# Save zeroed\n",
    "zeroed_data = {\n",
    "    \"prompt\": prompt + \" (zeroed padding)\",\n",
    "    \"embedding\": embedding_zeroed.tolist(),\n",
    "    \"shape\": [77, 768]\n",
    "}\n",
    "with open(output_dir / \"beaver_zeroed_padding.json\", 'w') as f:\n",
    "    json.dump(zeroed_data, f)\n",
    "\n",
    "print(\"\\nâœ“ Saved both embeddings to:\") \n",
    "print(f\"  {output_dir / 'beaver_normal.json'}\")\n",
    "print(f\"  {output_dir / 'beaver_zeroed_padding.json'}\")\n",
    "print(\"\\nYou can test both in Flux to see if padding affects the output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": "## Summary: What We Learned About Padding\n\n### Key Findings:\n\n1. **Padding Token Structure**:\n   - Padding uses a special token ID (usually the EOS token repeated)\n   - Appears in positions after real tokens up to position 77\n\n2. **Are Padding Embeddings Identical?**\n   - Padding at the **same position** across different prompts is nearly identical\n   - Padding at **different positions** within the same prompt may vary slightly (due to positional encodings)\n\n3. **Do They Affect Flux? YES, DRAMATICALLY!**\n   - **Normal padding** â†’ Generates expected content (beavers)\n   - **Zero padding** â†’ Generates random but coherent imagery (NOT beavers!)\n   - **Padding values matter significantly** to Flux's output\n   - This is a HUGE finding for creative manipulation!\n\n4. **Padding Variants Created**:\n   - uniform_pos_0.05 - very small positive values\n   - uniform_pos_0.1 - small positive values\n   - uniform_pos_0.2 - moderate positive values\n   - uniform_neg_0.1 - small negative values\n   - uniform_neg_0.2 - moderate negative values\n   - random_noise_std_0.1 - Gaussian noise\n   - scaled_50pct - 50% of normal padding magnitude\n\n5. **Practical Implications**:\n   - Padding is NOT just filler - it actively influences generation!\n   - We can use padding manipulation for creative effects\n   - Different padding values might produce different styles or themes\n   - This opens up a new dimension of embedding manipulation\n\n### Experiments to Run:\n\n1. Test all padding variants in Flux\n2. Compare outputs - look for patterns:\n   - Do positive/negative values produce different moods?\n   - Does random noise create more variation?\n   - What's the gradient effect as we vary magnitude?\n3. Try combining padding manipulation with token-level manipulations\n4. Explore if padding affects style more than content\n\n### Research Questions:\n\n- Why does padding affect output if it's supposed to be \"nothing\"?\n- Does Flux's attention mechanism weight padding tokens?\n- Can we use padding as a \"style knob\" while keeping content tokens intact?\n- What is the ideal padding for maximum creativity vs. prompt adherence?"
  },
  {
   "cell_type": "markdown",
   "id": "6hobjrdy2b",
   "source": "## Quick Reference: All Generated Embeddings\n\nUse these files in your Flux pipeline to test how different padding affects generation:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "97jmbp87347",
   "source": "# Create summary table\nimport pandas as pd\n\nsummary_data = []\n\n# Add normal\nsummary_data.append({\n    'Filename': 'beaver_normal.json',\n    'Description': 'Original CLIP padding',\n    'Expected Output': 'Beavers (baseline)',\n    'Padding Type': 'normal'\n})\n\n# Add zeroed\nsummary_data.append({\n    'Filename': 'beaver_zeroed_padding.json',\n    'Description': 'All padding = 0',\n    'Expected Output': 'Random coherent imagery',\n    'Padding Type': 'zeroed'\n})\n\n# Add all variants\nvariant_descriptions = {\n    'uniform_pos_0.05': 'Very small positive (0.05)',\n    'uniform_pos_0.1': 'Small positive (0.1)',\n    'uniform_pos_0.2': 'Moderate positive (0.2)',\n    'uniform_neg_0.1': 'Small negative (-0.1)',\n    'uniform_neg_0.2': 'Moderate negative (-0.2)',\n    'random_noise_std_0.1': 'Random Gaussian (Ïƒ=0.1)',\n    'scaled_50pct': '50% of normal padding'\n}\n\nfor name, desc in variant_descriptions.items():\n    summary_data.append({\n        'Filename': f'beaver_padding_{name}.json',\n        'Description': desc,\n        'Expected Output': '? (test in Flux!)',\n        'Padding Type': name\n    })\n\ndf = pd.DataFrame(summary_data)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUMMARY OF ALL GENERATED EMBEDDINGS\")\nprint(\"=\"*80)\nprint(df.to_string(index=False))\nprint(\"\\n\" + \"=\"*80)\nprint(f\"All files saved in: {output_dir}\")\nprint(\"=\"*80)\n\nprint(\"\\nðŸ“Š Testing Strategy:\")\nprint(\"  1. Start with beaver_normal.json (baseline)\")\nprint(\"  2. Test beaver_zeroed_padding.json (maximum deviation)\")\nprint(\"  3. Test moderate values (0.1, -0.1) to see direction effects\")\nprint(\"  4. Test higher values (0.2, -0.2) to see magnitude effects\")\nprint(\"  5. Test random_noise to see if structure matters\")\nprint(\"  6. Test scaled_50pct to see if relative scaling matters\")\nprint(\"\\nðŸŽ¨ Look for:\")\nprint(\"  - Style changes (lighting, mood, color palette)\")\nprint(\"  - Content changes (does it still show beavers?)\")\nprint(\"  - Coherence (is output still realistic?)\")\nprint(\"  - Patterns (do positive values trend one way, negative another?)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "hgn1l8n0odt",
   "source": "## Experiment 2: Moderate Padding Values\n\n**Discovery:** Zeroing out padding creates random but coherent imagery!\n\nNow let's test with more moderate values. CLIP embeddings typically have small values (roughly -0.3 to 0.3 range). Let's try:\n- Small uniform positive (0.1)\n- Small uniform negative (-0.1)\n- Moderate positive (0.2)\n- Moderate negative (-0.2)\n- Small random noise (Gaussian, std=0.1)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6c8hmm38cvq",
   "source": "# First, let's check what the actual value range of normal padding is\nprint(\"Normal padding statistics:\")\nprint(f\"  Min: {embedding_normal[num_real:].min():.6f}\")\nprint(f\"  Max: {embedding_normal[num_real:].max():.6f}\")\nprint(f\"  Mean: {embedding_normal[num_real:].mean():.6f}\")\nprint(f\"  Std: {embedding_normal[num_real:].std():.6f}\")\n\n# Also check real tokens for comparison\nprint(\"\\nReal token statistics:\")\nprint(f\"  Min: {embedding_normal[:num_real].min():.6f}\")\nprint(f\"  Max: {embedding_normal[:num_real].max():.6f}\")\nprint(f\"  Mean: {embedding_normal[:num_real].mean():.6f}\")\nprint(f\"  Std: {embedding_normal[:num_real].std():.6f}\")\n\n# Create different padding variants\npadding_variants = {}\n\n# 1. Uniform small positive\nemb_pos_01 = embedding_normal.copy()\nemb_pos_01[num_real:] = 0.1\npadding_variants[\"uniform_pos_0.1\"] = emb_pos_01\n\n# 2. Uniform small negative\nemb_neg_01 = embedding_normal.copy()\nemb_neg_01[num_real:] = -0.1\npadding_variants[\"uniform_neg_0.1\"] = emb_neg_01\n\n# 3. Uniform moderate positive\nemb_pos_02 = embedding_normal.copy()\nemb_pos_02[num_real:] = 0.2\npadding_variants[\"uniform_pos_0.2\"] = emb_pos_02\n\n# 4. Uniform moderate negative\nemb_neg_02 = embedding_normal.copy()\nemb_neg_02[num_real:] = -0.2\npadding_variants[\"uniform_neg_0.2\"] = emb_neg_02\n\n# 5. Small random noise (Gaussian)\nnp.random.seed(42)  # For reproducibility\nemb_random = embedding_normal.copy()\nrandom_padding = np.random.normal(0, 0.1, size=emb_random[num_real:].shape)\nemb_random[num_real:] = random_padding\npadding_variants[\"random_noise_std_0.1\"] = emb_random\n\n# 6. Very small uniform (0.05)\nemb_tiny = embedding_normal.copy()\nemb_tiny[num_real:] = 0.05\npadding_variants[\"uniform_pos_0.05\"] = emb_tiny\n\n# 7. Scaled down version of normal padding (50% magnitude)\nemb_scaled = embedding_normal.copy()\nemb_scaled[num_real:] = embedding_normal[num_real:] * 0.5\npadding_variants[\"scaled_50pct\"] = emb_scaled\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"Created padding variants:\")\nprint(\"=\"*70)\nfor name, emb in padding_variants.items():\n    padding_section = emb[num_real:]\n    print(f\"\\n{name}:\")\n    print(f\"  Min: {padding_section.min():.6f}\")\n    print(f\"  Max: {padding_section.max():.6f}\")\n    print(f\"  Mean: {padding_section.mean():.6f}\")\n    print(f\"  Std: {padding_section.std():.6f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "jorr3xid8o",
   "source": "# Visualize all padding variants\nn_variants = len(padding_variants) + 2  # +2 for normal and zeroed\nfig, axes = plt.subplots(n_variants, 1, figsize=(15, 3*n_variants))\n\n# Plot normal\nax = axes[0]\nim = ax.imshow(embedding_normal.T, aspect='auto', cmap='RdBu_r', vmin=-0.5, vmax=0.5)\nax.axvline(x=num_real-0.5, color='lime', linewidth=2)\nax.set_title('NORMAL PADDING (original)', fontweight='bold', fontsize=12)\nax.set_ylabel('Dim')\nplt.colorbar(im, ax=ax)\n\n# Plot zeroed\nax = axes[1]\nim = ax.imshow(embedding_zeroed.T, aspect='auto', cmap='RdBu_r', vmin=-0.5, vmax=0.5)\nax.axvline(x=num_real-0.5, color='lime', linewidth=2)\nax.set_title('ZEROED PADDING', fontweight='bold', fontsize=12)\nax.set_ylabel('Dim')\nplt.colorbar(im, ax=ax)\n\n# Plot each variant\nfor idx, (name, emb) in enumerate(padding_variants.items(), start=2):\n    ax = axes[idx]\n    im = ax.imshow(emb.T, aspect='auto', cmap='RdBu_r', vmin=-0.5, vmax=0.5)\n    ax.axvline(x=num_real-0.5, color='lime', linewidth=2)\n    ax.set_title(f'PADDING: {name}', fontweight='bold', fontsize=12)\n    ax.set_ylabel('Dim')\n    plt.colorbar(im, ax=ax)\n\naxes[-1].set_xlabel('Token Position', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"âœ“ Visualization complete\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8ntxmnsnteu",
   "source": "# Save all variants to JSON files for testing in Flux\nprint(\"Saving all padding variants...\")\nprint(\"=\"*70)\n\nsaved_files = []\n\n# Save each variant\nfor name, emb in padding_variants.items():\n    filename = f\"beaver_padding_{name}.json\"\n    filepath = output_dir / filename\n    \n    data = {\n        \"prompt\": f\"{prompt} (padding: {name})\",\n        \"embedding\": emb.tolist(),\n        \"shape\": [77, 768],\n        \"padding_type\": name\n    }\n    \n    with open(filepath, 'w') as f:\n        json.dump(data, f)\n    \n    saved_files.append(filename)\n    print(f\"âœ“ Saved: {filename}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(f\"âœ“ All {len(saved_files)} variants saved to:\")\nprint(f\"  {output_dir}\")\nprint(\"\\n\" + \"=\"*70)\nprint(\"Test each in Flux to see how padding values affect generation!\")\nprint(\"\\nVariants to test:\")\nprint(\"1. beaver_normal.json - baseline (should produce beavers)\")\nprint(\"2. beaver_zeroed_padding.json - random coherent images\")\nfor f in saved_files:\n    print(f\"3+. {f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}