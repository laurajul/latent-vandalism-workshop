{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Understanding Padding Tokens in CLIP Embeddings\n",
    "\n",
    "## The Question\n",
    "\n",
    "When we have a prompt like **\"a beaver with blue teeth\"**, it only uses maybe 10 tokens out of 77 total positions. The remaining 67 positions are **padding tokens**.\n",
    "\n",
    "**Key Questions:**\n",
    "1. Are padding tokens always the same?\n",
    "2. How do they affect the final embedding?\n",
    "3. Do padding embeddings at position 10 differ from padding at position 50?\n",
    "4. Can we manipulate padding tokens to affect Flux output?\n",
    "\n",
    "Let's investigate!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load CLIP text model\n",
    "model_name = \"openai/clip-vit-large-patch14\"\n",
    "tokenizer = CLIPTokenizer.from_pretrained(model_name)\n",
    "model = CLIPTextModel.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úì Model loaded\")\n",
    "print(f\"  Vocab size: {tokenizer.vocab_size}\")\n",
    "print(f\"  Max length: {tokenizer.model_max_length}\")\n",
    "print(f\"  Pad token: '{tokenizer.pad_token}' (ID: {tokenizer.pad_token_id})\")\n",
    "print(f\"  EOS token: '{tokenizer.eos_token}' (ID: {tokenizer.eos_token_id})\")\n",
    "print(f\"  BOS token: '{tokenizer.bos_token}' (ID: {tokenizer.bos_token_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01u0ko7by8mn",
   "source": "## Prompt Input and Tokenization",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "91c944efjrw",
   "source": "import ipywidgets as widgets\nfrom IPython.display import display, clear_output, HTML\n\n# Create prompt input widget\nprompt_input = widgets.Textarea(\n    value='a beaver with blue teeth',\n    placeholder='Enter your prompt here',\n    description='Prompt:',\n    style={'description_width': 'initial'},\n    layout=widgets.Layout(width='600px', height='80px')\n)\n\ntokenize_button = widgets.Button(\n    description='Tokenize & Analyze',\n    button_style='info',\n    layout=widgets.Layout(width='200px')\n)\n\ntokenization_output = widgets.Output()\n\n# Global variables to store tokenization results\nprompt = None\ntokens = None\ntoken_ids = None\nattention_mask = None\nnum_real_tokens = None\nfilename_prefix = None\n\ndef visualize_tokenization(b):\n    global prompt, tokens, token_ids, attention_mask, num_real_tokens, filename_prefix\n    \n    with tokenization_output:\n        clear_output(wait=True)\n        \n        prompt = prompt_input.value.strip()\n        \n        if not prompt:\n            print(\"‚ùå Please enter a prompt!\")\n            return\n        \n        # Tokenize\n        tokens = tokenizer(\n            prompt,\n            padding=\"max_length\",\n            max_length=77,\n            truncation=True,\n            return_tensors=\"pt\"\n        )\n        \n        token_ids = tokens['input_ids'][0].tolist()\n        attention_mask = tokens['attention_mask'][0].tolist()\n        num_real_tokens = sum(attention_mask)\n        num_padding = 77 - num_real_tokens\n        \n        # Decode individual tokens\n        decoded_tokens = []\n        for tid in token_ids[:num_real_tokens]:\n            decoded = tokenizer.decode([tid])\n            decoded_tokens.append(decoded)\n        \n        # Extract tokens for filename (skip special tokens)\n        filename_tokens = []\n        for tid in token_ids:\n            decoded = tokenizer.decode([tid]).strip()\n            if decoded and decoded not in ['<|startoftext|>', '<|endoftext|>', '']:\n                cleaned = decoded.replace('</w>', '').strip()\n                if cleaned:\n                    filename_tokens.append(cleaned)\n                if len(filename_tokens) >= 4:\n                    break\n        \n        filename_prefix = \"_\".join(filename_tokens)\n        \n        # Create visualization\n        print(\"=\"*80)\n        print(\"TOKENIZATION ANALYSIS\")\n        print(\"=\"*80)\n        print(f\"\\nOriginal Prompt: \\\"{prompt}\\\"\")\n        print(f\"\\n{'='*80}\")\n        print(f\"Token Breakdown:\")\n        print(f\"{'='*80}\\n\")\n        \n        # Show token breakdown with visual separation\n        token_display = []\n        for i, decoded in enumerate(decoded_tokens):\n            # Clean display (remove special markers for display)\n            clean = decoded.strip().replace('</w>', '').replace('<|startoftext|>', '[START]').replace('<|endoftext|>', '[END]')\n            \n            # Add separator\n            if i > 0 and decoded not in ['<|startoftext|>', '<|endoftext|>']:\n                token_display.append(\"-\")\n            token_display.append(clean)\n        \n        # Print with visual highlighting\n        visual_tokens = \"\".join(token_display)\n        print(f\"  {visual_tokens}\")\n        print()\n        \n        # Show detailed token list\n        print(f\"{'='*80}\")\n        print(f\"Detailed Token List:\")\n        print(f\"{'='*80}\")\n        print(f\"{'Position':<10} {'Token ID':<12} {'Type':<15} {'Decoded':<30}\")\n        print(\"-\" * 80)\n        \n        for i in range(min(num_real_tokens, 15)):  # Show first 15 real tokens\n            tid = token_ids[i]\n            decoded = tokenizer.decode([tid])\n            \n            # Determine type\n            if '<|startoftext|>' in decoded:\n                token_type = 'START'\n            elif '<|endoftext|>' in decoded:\n                token_type = 'END'\n            else:\n                token_type = 'TEXT'\n            \n            print(f\"{i:<10} {tid:<12} {token_type:<15} '{decoded.strip()}'\")\n        \n        if num_real_tokens > 15:\n            print(f\"... ({num_real_tokens - 15} more real tokens)\")\n        \n        # Summary statistics\n        print(f\"\\n{'='*80}\")\n        print(f\"SUMMARY:\")\n        print(f\"{'='*80}\")\n        print(f\"  ‚úì Real tokens:    {num_real_tokens:>3} tokens\")\n        print(f\"  ‚úì Padding tokens: {num_padding:>3} tokens\")\n        print(f\"  ‚úì Total:          {77:>3} tokens\")\n        print(f\"  ‚úì Filename prefix: '{filename_prefix}'\")\n        print(f\"{'='*80}\")\n        \n        # Visual bar chart\n        real_bar = \"‚ñà\" * (num_real_tokens // 2)\n        padding_bar = \"‚ñë\" * (num_padding // 2)\n        \n        print(f\"\\nVisual representation (each char ‚âà 2 tokens):\")\n        print(f\"  Real:    [{real_bar}]\")\n        print(f\"  Padding: [{padding_bar}]\")\n        print()\n        \n        print(\"‚úì Ready to generate padding experiments!\")\n        print(\"  Run the cells below to create all padding variants.\")\n\ntokenize_button.on_click(visualize_tokenization)\n\nprint(\"Enter your prompt and click 'Tokenize & Analyze' to begin:\")\ndisplay(prompt_input, tokenize_button, tokenization_output)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "investigate-tokens",
   "metadata": {},
   "source": [
    "## Investigation 1: What Are the Token IDs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "investigate-tokens-cell",
   "metadata": {},
   "outputs": [],
   "source": "# NOTE: Tokenization is now done via the interactive widget above!\n# This cell shows the raw tokenization details for reference.\n\nif prompt is None or tokens is None:\n    print(\"‚ùå Please run the 'Prompt Input and Tokenization' cell first!\")\n    print(\"   Enter a prompt and click 'Tokenize & Analyze'\")\nelse:\n    print(f\"Detailed tokenization for: '{prompt}'\")\n    print(f\"\\nToken IDs (first 15 positions):\")\n    print(\"Position | Token ID | Attention | Decoded\")\n    print(\"-\" * 60)\n    for i in range(min(15, len(token_ids))):\n        decoded = tokenizer.decode([token_ids[i]])\n        print(f\"{i:8} | {token_ids[i]:8} | {attention_mask[i]:9} | '{decoded}'\")\n    \n    print(\"\\n...\")\n    print(\"\\nLast 5 positions:\")\n    for i in range(72, 77):\n        decoded = tokenizer.decode([token_ids[i]])\n        print(f\"{i:8} | {token_ids[i]:8} | {attention_mask[i]:9} | '{decoded}'\")"
  },
  {
   "cell_type": "markdown",
   "id": "investigate-embeddings",
   "metadata": {},
   "source": [
    "## Investigation 2: Are Padding Embeddings Identical?\n",
    "\n",
    "Let's check if padding embeddings at different positions are the same or different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "investigate-embeddings-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embedding\n",
    "with torch.no_grad():\n",
    "    tokens_device = {k: v.to(device) for k, v in tokens.items()}\n",
    "    outputs = model(**tokens_device)\n",
    "    embedding = outputs.last_hidden_state[0]  # [77, 768]\n",
    "\n",
    "embedding_np = embedding.cpu().numpy()\n",
    "\n",
    "print(f\"Embedding shape: {embedding_np.shape}\")\n",
    "print(f\"\\nLet's compare padding embeddings at different positions...\\n\")\n",
    "\n",
    "# Find first padding position\n",
    "first_padding_pos = num_real_tokens\n",
    "print(f\"First padding position: {first_padding_pos}\")\n",
    "\n",
    "# Compare padding embeddings at different positions\n",
    "if num_padding > 1:\n",
    "    padding_positions = [first_padding_pos, first_padding_pos + 10, first_padding_pos + 20, 76]\n",
    "    padding_positions = [p for p in padding_positions if p < 77]\n",
    "    \n",
    "    print(f\"\\nComparing padding embeddings at positions: {padding_positions}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, pos in enumerate(padding_positions):\n",
    "        emb = embedding_np[pos]\n",
    "        print(f\"\\nPosition {pos}:\")\n",
    "        print(f\"  First 10 values: {emb[:10]}\")\n",
    "        print(f\"  Mean: {emb.mean():.6f}\")\n",
    "        print(f\"  Std: {emb.std():.6f}\")\n",
    "        print(f\"  L2 norm: {np.linalg.norm(emb):.6f}\")\n",
    "    \n",
    "    # Calculate pairwise differences\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Pairwise Cosine Similarities Between Padding Embeddings:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i in range(len(padding_positions)):\n",
    "        for j in range(i+1, len(padding_positions)):\n",
    "            pos_i = padding_positions[i]\n",
    "            pos_j = padding_positions[j]\n",
    "            emb_i = embedding_np[pos_i]\n",
    "            emb_j = embedding_np[pos_j]\n",
    "            \n",
    "            # Cosine similarity\n",
    "            cos_sim = np.dot(emb_i, emb_j) / (np.linalg.norm(emb_i) * np.linalg.norm(emb_j))\n",
    "            \n",
    "            # L2 distance\n",
    "            l2_dist = np.linalg.norm(emb_i - emb_j)\n",
    "            \n",
    "            print(f\"Positions {pos_i} vs {pos_j}:\")\n",
    "            print(f\"  Cosine similarity: {cos_sim:.8f}\")\n",
    "            print(f\"  L2 distance: {l2_dist:.6f}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-prompts",
   "metadata": {},
   "source": [
    "## Investigation 3: Are Padding Embeddings the Same Across Different Prompts?\n",
    "\n",
    "Do the padding embeddings change when we use different prompts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-prompts-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple prompts of different lengths\n",
    "test_prompts = [\n",
    "    \"cat\",\n",
    "    \"a red cat\",\n",
    "    \"a beaver with blue teeth\",\n",
    "    \"an elephant standing in a field of flowers\",\n",
    "]\n",
    "\n",
    "padding_embeddings = {}\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    # Tokenize\n",
    "    tokens = tokenizer(\n",
    "        prompt,\n",
    "        padding=\"max_length\",\n",
    "        max_length=77,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Get embedding\n",
    "    with torch.no_grad():\n",
    "        tokens_device = {k: v.to(device) for k, v in tokens.items()}\n",
    "        outputs = model(**tokens_device)\n",
    "        embedding = outputs.last_hidden_state[0].cpu().numpy()\n",
    "    \n",
    "    # Find padding positions\n",
    "    attention_mask = tokens['attention_mask'][0].tolist()\n",
    "    num_real = sum(attention_mask)\n",
    "    first_padding = num_real\n",
    "    \n",
    "    # Store padding embedding at a consistent position (e.g., position 50)\n",
    "    if first_padding < 50:\n",
    "        padding_embeddings[prompt] = {\n",
    "            'num_real_tokens': num_real,\n",
    "            'first_padding': first_padding,\n",
    "            'padding_at_50': embedding[50],\n",
    "            'padding_at_76': embedding[76]\n",
    "        }\n",
    "    \n",
    "    print(f\"Prompt: '{prompt}'\")\n",
    "    print(f\"  Real tokens: {num_real}\")\n",
    "    print(f\"  First padding position: {first_padding}\")\n",
    "    print()\n",
    "\n",
    "# Compare padding embeddings across prompts\n",
    "print(\"=\"*60)\n",
    "print(\"Comparing Padding at Position 50 Across Different Prompts:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "prompts_list = list(padding_embeddings.keys())\n",
    "for i in range(len(prompts_list)):\n",
    "    for j in range(i+1, len(prompts_list)):\n",
    "        prompt_i = prompts_list[i]\n",
    "        prompt_j = prompts_list[j]\n",
    "        \n",
    "        emb_i = padding_embeddings[prompt_i]['padding_at_50']\n",
    "        emb_j = padding_embeddings[prompt_j]['padding_at_50']\n",
    "        \n",
    "        cos_sim = np.dot(emb_i, emb_j) / (np.linalg.norm(emb_i) * np.linalg.norm(emb_j))\n",
    "        l2_dist = np.linalg.norm(emb_i - emb_j)\n",
    "        \n",
    "        print(f\"\\n'{prompt_i[:30]}...' vs '{prompt_j[:30]}...'\")\n",
    "        print(f\"  Cosine similarity: {cos_sim:.10f}\")\n",
    "        print(f\"  L2 distance: {l2_dist:.10f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if cos_sim > 0.9999:\n",
    "    print(\"‚úì CONCLUSION: Padding embeddings at the same position are\")\n",
    "    print(\"  NEARLY IDENTICAL across different prompts!\")\n",
    "else:\n",
    "    print(\"‚úì CONCLUSION: Padding embeddings differ across prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize",
   "metadata": {},
   "source": [
    "## Visualization: Real Tokens vs Padding Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"a beaver with blue teeth\" prompt\n",
    "prompt = \"a beaver with blue teeth\"\n",
    "\n",
    "tokens = tokenizer(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=77,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens_device = {k: v.to(device) for k, v in tokens.items()}\n",
    "    outputs = model(**tokens_device)\n",
    "    embedding = outputs.last_hidden_state[0].cpu().numpy()\n",
    "\n",
    "attention_mask = tokens['attention_mask'][0].tolist()\n",
    "num_real = sum(attention_mask)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Heatmap of embedding\n",
    "ax1 = axes[0]\n",
    "im = ax1.imshow(embedding.T, aspect='auto', cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "ax1.axvline(x=num_real-0.5, color='lime', linewidth=3, label='Padding starts here')\n",
    "ax1.set_xlabel('Token Position', fontsize=12)\n",
    "ax1.set_ylabel('Embedding Dimension', fontsize=12)\n",
    "ax1.set_title(f'CLIP Text Embedding: \"{prompt}\"\\n(Green line = where padding starts)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "plt.colorbar(im, ax=ax1, label='Embedding Value')\n",
    "\n",
    "# Plot 2: L2 norms of each token embedding\n",
    "ax2 = axes[1]\n",
    "norms = [np.linalg.norm(embedding[i]) for i in range(77)]\n",
    "colors = ['steelblue' if i < num_real else 'orange' for i in range(77)]\n",
    "ax2.bar(range(77), norms, color=colors, alpha=0.7)\n",
    "ax2.axvline(x=num_real-0.5, color='lime', linewidth=3, linestyle='--', \n",
    "            label='Padding starts here')\n",
    "ax2.set_xlabel('Token Position', fontsize=12)\n",
    "ax2.set_ylabel('L2 Norm', fontsize=12)\n",
    "ax2.set_title('L2 Norm of Each Token Embedding\\n(Blue = real tokens, Orange = padding)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Visualization complete\")\n",
    "print(f\"  Real tokens: {num_real}\")\n",
    "print(f\"  Padding tokens: {77 - num_real}\")\n",
    "print(f\"  Average norm of real tokens: {np.mean(norms[:num_real]):.4f}\")\n",
    "print(f\"  Average norm of padding tokens: {np.mean(norms[num_real:]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experiment",
   "metadata": {},
   "source": [
    "## Experiment: What If We Zero Out Padding?\n",
    "\n",
    "What happens if we replace padding embeddings with zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experiment-cell",
   "metadata": {},
   "outputs": [],
   "source": "import json\n\n# Check if prompt has been tokenized\nif prompt is None or tokens is None:\n    print(\"‚ùå Please run the 'Prompt Input and Tokenization' cell first!\")\n    print(\"   Enter a prompt and click 'Tokenize & Analyze'\")\nelse:\n    print(f\"Using prompt: \\\"{prompt}\\\"\")\n    print(f\"Filename prefix: '{filename_prefix}'\")\n    print(f\"Real tokens: {num_real_tokens}, Padding tokens: {77 - num_real_tokens}\")\n    print(\"\\n\" + \"=\"*70)\n    \n    # Generate normal embedding\n    with torch.no_grad():\n        tokens_device = {k: v.to(device) for k, v in tokens.items()}\n        outputs = model(**tokens_device)\n        embedding_normal = outputs.last_hidden_state[0].cpu().numpy()\n    \n    # Create version with zeroed padding\n    embedding_zeroed = embedding_normal.copy()\n    embedding_zeroed[num_real_tokens:] = 0  # Zero out all padding positions\n    \n    print(f\"\\nOriginal embedding stats:\")\n    print(f\"  Mean: {embedding_normal.mean():.6f}\")\n    print(f\"  Std: {embedding_normal.std():.6f}\")\n    print(f\"  Norm: {np.linalg.norm(embedding_normal):.6f}\")\n    \n    print(f\"\\nZeroed padding embedding stats:\")\n    print(f\"  Mean: {embedding_zeroed.mean():.6f}\")\n    print(f\"  Std: {embedding_zeroed.std():.6f}\")\n    print(f\"  Norm: {np.linalg.norm(embedding_zeroed):.6f}\")\n    \n    # Visualize difference\n    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n    \n    # Original\n    im1 = axes[0].imshow(embedding_normal.T, aspect='auto', cmap='RdBu_r', vmin=-1, vmax=1)\n    axes[0].axvline(x=num_real_tokens-0.5, color='lime', linewidth=2)\n    axes[0].set_title(f'Original Embedding: \"{prompt}\"', fontweight='bold')\n    axes[0].set_ylabel('Dimension')\n    plt.colorbar(im1, ax=axes[0])\n    \n    # Zeroed\n    im2 = axes[1].imshow(embedding_zeroed.T, aspect='auto', cmap='RdBu_r', vmin=-1, vmax=1)\n    axes[1].axvline(x=num_real_tokens-0.5, color='lime', linewidth=2)\n    axes[1].set_title('Zeroed Padding Embedding', fontweight='bold')\n    axes[1].set_ylabel('Dimension')\n    plt.colorbar(im2, ax=axes[1])\n    \n    # Difference\n    diff = embedding_normal - embedding_zeroed\n    im3 = axes[2].imshow(diff.T, aspect='auto', cmap='RdBu_r', vmin=-1, vmax=1)\n    axes[2].axvline(x=num_real_tokens-0.5, color='lime', linewidth=2)\n    axes[2].set_title('Difference (what we removed)', fontweight='bold')\n    axes[2].set_xlabel('Token Position')\n    axes[2].set_ylabel('Dimension')\n    plt.colorbar(im3, ax=axes[2])\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Save both versions\n    current_dir = Path(os.getcwd())\n    output_dir = current_dir.parent / \"data\" / \"embeddings\" / \"CLIP\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Save normal\n    normal_data = {\n        \"prompt\": prompt,\n        \"embedding\": embedding_normal.tolist(),\n        \"shape\": [77, 768]\n    }\n    with open(output_dir / f\"{filename_prefix}_normal.json\", 'w') as f:\n        json.dump(normal_data, f)\n    \n    # Save zeroed\n    zeroed_data = {\n        \"prompt\": prompt + \" (zeroed padding)\",\n        \"embedding\": embedding_zeroed.tolist(),\n        \"shape\": [77, 768]\n    }\n    with open(output_dir / f\"{filename_prefix}_zeroed_padding.json\", 'w') as f:\n        json.dump(zeroed_data, f)\n    \n    print(\"\\n‚úì Saved both embeddings to:\") \n    print(f\"  {output_dir / f'{filename_prefix}_normal.json'}\")\n    print(f\"  {output_dir / f'{filename_prefix}_zeroed_padding.json'}\")\n    print(\"\\nYou can test both in Flux to see if padding affects the output!\")"
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": "## Summary: What We Learned About Padding\n\n### Key Findings:\n\n1. **Padding Token Structure**:\n   - Padding uses a special token ID (usually the EOS token repeated)\n   - Appears in positions after real tokens up to position 77\n\n2. **Are Padding Embeddings Identical?**\n   - Padding at the **same position** across different prompts is nearly identical\n   - Padding at **different positions** within the same prompt may vary slightly (due to positional encodings)\n\n3. **Do They Affect Flux? YES, DRAMATICALLY!**\n   - **Normal padding** ‚Üí Generates expected content (beavers)\n   - **Zero padding** ‚Üí Generates random but coherent imagery (NOT beavers!)\n   - **Padding values matter significantly** to Flux's output\n   - This is a HUGE finding for creative manipulation!\n\n4. **Padding Variants Created**:\n   - uniform_pos_0.05 - very small positive values\n   - uniform_pos_0.1 - small positive values\n   - uniform_pos_0.2 - moderate positive values\n   - uniform_neg_0.1 - small negative values\n   - uniform_neg_0.2 - moderate negative values\n   - random_noise_std_0.1 - Gaussian noise\n   - scaled_50pct - 50% of normal padding magnitude\n\n5. **Practical Implications**:\n   - Padding is NOT just filler - it actively influences generation!\n   - We can use padding manipulation for creative effects\n   - Different padding values might produce different styles or themes\n   - This opens up a new dimension of embedding manipulation\n\n### Experiments to Run:\n\n1. Test all padding variants in Flux\n2. Compare outputs - look for patterns:\n   - Do positive/negative values produce different moods?\n   - Does random noise create more variation?\n   - What's the gradient effect as we vary magnitude?\n3. Try combining padding manipulation with token-level manipulations\n4. Explore if padding affects style more than content\n\n### Research Questions:\n\n- Why does padding affect output if it's supposed to be \"nothing\"?\n- Does Flux's attention mechanism weight padding tokens?\n- Can we use padding as a \"style knob\" while keeping content tokens intact?\n- What is the ideal padding for maximum creativity vs. prompt adherence?"
  },
  {
   "cell_type": "markdown",
   "id": "6hobjrdy2b",
   "source": "## Quick Reference: All Generated Embeddings\n\nUse these files in your Flux pipeline to test how different padding affects generation:\n\n**Filename Format**: `{token1}_{token2}_{token3}_{token4}_{variant}.json`\n\nFor example, with prompt \"a beaver with blue teeth\":\n- `a_beaver_with_blue_normal.json`\n- `a_beaver_with_blue_zeroed_padding.json`\n- `a_beaver_with_blue_padding_uniform_pos_0.1.json`\n- etc.\n\nThis way, you can run the notebook with different prompts and get unique filenames!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "97jmbp87347",
   "source": "# Create summary table\nimport pandas as pd\n\nsummary_data = []\n\n# Add normal\nsummary_data.append({\n    'Filename': f'{filename_prefix}_normal.json',\n    'Description': 'Original CLIP padding',\n    'Expected Output': 'Expected content (baseline)',\n    'Padding Type': 'normal'\n})\n\n# Add zeroed\nsummary_data.append({\n    'Filename': f'{filename_prefix}_zeroed_padding.json',\n    'Description': 'All padding = 0',\n    'Expected Output': 'Random coherent imagery',\n    'Padding Type': 'zeroed'\n})\n\n# Add all variants\nvariant_descriptions = {\n    'uniform_pos_0.05': 'Very small positive (0.05)',\n    'uniform_pos_0.1': 'Small positive (0.1)',\n    'uniform_pos_0.2': 'Moderate positive (0.2)',\n    'uniform_neg_0.1': 'Small negative (-0.1)',\n    'uniform_neg_0.2': 'Moderate negative (-0.2)',\n    'random_noise_std_0.1': 'Random Gaussian (œÉ=0.1)',\n    'scaled_50pct': '50% of normal padding'\n}\n\nfor name, desc in variant_descriptions.items():\n    summary_data.append({\n        'Filename': f'{filename_prefix}_padding_{name}.json',\n        'Description': desc,\n        'Expected Output': '? (test in Flux!)',\n        'Padding Type': name\n    })\n\ndf = pd.DataFrame(summary_data)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUMMARY OF ALL GENERATED EMBEDDINGS\")\nprint(\"=\"*80)\nprint(f\"Prompt: '{prompt}'\")\nprint(f\"Filename prefix: '{filename_prefix}'\")\nprint(\"=\"*80)\nprint(df.to_string(index=False))\nprint(\"\\n\" + \"=\"*80)\nprint(f\"All files saved in: {output_dir}\")\nprint(\"=\"*80)\n\nprint(\"\\nüìä Testing Strategy:\")\nprint(f\"  1. Start with {filename_prefix}_normal.json (baseline)\")\nprint(f\"  2. Test {filename_prefix}_zeroed_padding.json (maximum deviation)\")\nprint(\"  3. Test moderate values (0.1, -0.1) to see direction effects\")\nprint(\"  4. Test higher values (0.2, -0.2) to see magnitude effects\")\nprint(\"  5. Test random_noise to see if structure matters\")\nprint(\"  6. Test scaled_50pct to see if relative scaling matters\")\nprint(\"\\nüé® Look for:\")\nprint(\"  - Style changes (lighting, mood, color palette)\")\nprint(\"  - Content changes (does it still match the prompt?)\")\nprint(\"  - Coherence (is output still realistic?)\")\nprint(\"  - Patterns (do positive values trend one way, negative another?)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "hgn1l8n0odt",
   "source": "## Experiment 2: Moderate Padding Values\n\n**Discovery:** Zeroing out padding creates random but coherent imagery!\n\nNow let's test with more moderate values. CLIP embeddings typically have small values (roughly -0.3 to 0.3 range). Let's try:\n- Small uniform positive (0.1)\n- Small uniform negative (-0.1)\n- Moderate positive (0.2)\n- Moderate negative (-0.2)\n- Small random noise (Gaussian, std=0.1)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6c8hmm38cvq",
   "source": "# Check if embeddings have been generated\nif 'embedding_normal' not in globals() or embedding_normal is None:\n    print(\"‚ùå Please run the 'Experiment: Zero Out Padding' cell first!\")\nelse:\n    print(f\"Analyzing padding for prompt: \\\"{prompt}\\\"\")\n    print(\"=\"*70)\n    \n    # First, let's check what the actual value range of normal padding is\n    print(\"\\nNormal padding statistics:\")\n    print(f\"  Min: {embedding_normal[num_real_tokens:].min():.6f}\")\n    print(f\"  Max: {embedding_normal[num_real_tokens:].max():.6f}\")\n    print(f\"  Mean: {embedding_normal[num_real_tokens:].mean():.6f}\")\n    print(f\"  Std: {embedding_normal[num_real_tokens:].std():.6f}\")\n    \n    # Also check real tokens for comparison\n    print(\"\\nReal token statistics:\")\n    print(f\"  Min: {embedding_normal[:num_real_tokens].min():.6f}\")\n    print(f\"  Max: {embedding_normal[:num_real_tokens].max():.6f}\")\n    print(f\"  Mean: {embedding_normal[:num_real_tokens].mean():.6f}\")\n    print(f\"  Std: {embedding_normal[:num_real_tokens].std():.6f}\")\n    \n    # Create different padding variants\n    padding_variants = {}\n    \n    # 1. Uniform small positive\n    emb_pos_01 = embedding_normal.copy()\n    emb_pos_01[num_real_tokens:] = 0.1\n    padding_variants[\"uniform_pos_0.1\"] = emb_pos_01\n    \n    # 2. Uniform small negative\n    emb_neg_01 = embedding_normal.copy()\n    emb_neg_01[num_real_tokens:] = -0.1\n    padding_variants[\"uniform_neg_0.1\"] = emb_neg_01\n    \n    # 3. Uniform moderate positive\n    emb_pos_02 = embedding_normal.copy()\n    emb_pos_02[num_real_tokens:] = 0.2\n    padding_variants[\"uniform_pos_0.2\"] = emb_pos_02\n    \n    # 4. Uniform moderate negative\n    emb_neg_02 = embedding_normal.copy()\n    emb_neg_02[num_real_tokens:] = -0.2\n    padding_variants[\"uniform_neg_0.2\"] = emb_neg_02\n    \n    # 5. Small random noise (Gaussian)\n    np.random.seed(42)  # For reproducibility\n    emb_random = embedding_normal.copy()\n    random_padding = np.random.normal(0, 0.1, size=emb_random[num_real_tokens:].shape)\n    emb_random[num_real_tokens:] = random_padding\n    padding_variants[\"random_noise_std_0.1\"] = emb_random\n    \n    # 6. Very small uniform (0.05)\n    emb_tiny = embedding_normal.copy()\n    emb_tiny[num_real_tokens:] = 0.05\n    padding_variants[\"uniform_pos_0.05\"] = emb_tiny\n    \n    # 7. Scaled down version of normal padding (50% magnitude)\n    emb_scaled = embedding_normal.copy()\n    emb_scaled[num_real_tokens:] = embedding_normal[num_real_tokens:] * 0.5\n    padding_variants[\"scaled_50pct\"] = emb_scaled\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"Created padding variants:\")\n    print(\"=\"*70)\n    for name, emb in padding_variants.items():\n        padding_section = emb[num_real_tokens:]\n        print(f\"\\n{name}:\")\n        print(f\"  Min: {padding_section.min():.6f}\")\n        print(f\"  Max: {padding_section.max():.6f}\")\n        print(f\"  Mean: {padding_section.mean():.6f}\")\n        print(f\"  Std: {padding_section.std():.6f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "jorr3xid8o",
   "source": "# Visualize all padding variants\nif 'padding_variants' not in globals() or not padding_variants:\n    print(\"‚ùå Please run the 'Moderate Padding Values' cell first!\")\nelse:\n    n_variants = len(padding_variants) + 2  # +2 for normal and zeroed\n    fig, axes = plt.subplots(n_variants, 1, figsize=(15, 3*n_variants))\n    \n    # Plot normal\n    ax = axes[0]\n    im = ax.imshow(embedding_normal.T, aspect='auto', cmap='RdBu_r', vmin=-0.5, vmax=0.5)\n    ax.axvline(x=num_real_tokens-0.5, color='lime', linewidth=2)\n    ax.set_title(f'NORMAL PADDING: \"{prompt}\"', fontweight='bold', fontsize=12)\n    ax.set_ylabel('Dim')\n    plt.colorbar(im, ax=ax)\n    \n    # Plot zeroed\n    ax = axes[1]\n    im = ax.imshow(embedding_zeroed.T, aspect='auto', cmap='RdBu_r', vmin=-0.5, vmax=0.5)\n    ax.axvline(x=num_real_tokens-0.5, color='lime', linewidth=2)\n    ax.set_title('ZEROED PADDING', fontweight='bold', fontsize=12)\n    ax.set_ylabel('Dim')\n    plt.colorbar(im, ax=ax)\n    \n    # Plot each variant\n    for idx, (name, emb) in enumerate(padding_variants.items(), start=2):\n        ax = axes[idx]\n        im = ax.imshow(emb.T, aspect='auto', cmap='RdBu_r', vmin=-0.5, vmax=0.5)\n        ax.axvline(x=num_real_tokens-0.5, color='lime', linewidth=2)\n        ax.set_title(f'PADDING: {name}', fontweight='bold', fontsize=12)\n        ax.set_ylabel('Dim')\n        plt.colorbar(im, ax=ax)\n    \n    axes[-1].set_xlabel('Token Position', fontsize=12)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"‚úì Visualization complete\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8ntxmnsnteu",
   "source": "# Save all variants to JSON files for testing in Flux\nif 'padding_variants' not in globals() or not padding_variants:\n    print(\"‚ùå Please run the 'Moderate Padding Values' cell first!\")\nelse:\n    print(\"Saving all padding variants...\")\n    print(\"=\"*70)\n    \n    saved_files = []\n    \n    # Make sure output directory exists\n    current_dir = Path(os.getcwd())\n    output_dir = current_dir.parent / \"data\" / \"embeddings\" / \"CLIP\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Save each variant\n    for name, emb in padding_variants.items():\n        filename = f\"{filename_prefix}_padding_{name}.json\"\n        filepath = output_dir / filename\n        \n        data = {\n            \"prompt\": f\"{prompt} (padding: {name})\",\n            \"embedding\": emb.tolist(),\n            \"shape\": [77, 768],\n            \"padding_type\": name\n        }\n        \n        with open(filepath, 'w') as f:\n            json.dump(data, f)\n        \n        saved_files.append(filename)\n        print(f\"‚úì Saved: {filename}\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(f\"‚úì All {len(saved_files)} variants saved to:\")\n    print(f\"  {output_dir}\")\n    print(\"\\n\" + \"=\"*70)\n    print(\"Test each in Flux to see how padding values affect generation!\")\n    print(\"\\nVariants to test:\")\n    print(f\"1. {filename_prefix}_normal.json - baseline (should produce expected content)\")\n    print(f\"2. {filename_prefix}_zeroed_padding.json - random coherent images\")\n    for f in saved_files:\n        print(f\"3+. {f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}