{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 Embedding Manipulation for FLUX\n",
    "\n",
    "This notebook lets you:\n",
    "1. Generate T5 embeddings from text prompts\n",
    "2. Save/load embeddings as JSON\n",
    "3. Manually edit embedding values\n",
    "4. Apply custom attention masks\n",
    "5. Generate images with FLUX using modified embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Run this cell first to install required packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from diffusers import FluxPipeline\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image as IPImage\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create models directory\n",
    "MODELS_DIR = \"data/models\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "print(f\"Models will be stored in: {os.path.abspath(MODELS_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T13:37:19.932668Z",
     "iopub.status.busy": "2026-01-09T13:37:19.932555Z",
     "iopub.status.idle": "2026-01-09T13:40:42.560501Z",
     "shell.execute_reply": "2026-01-09T13:40:42.559485Z",
     "shell.execute_reply.started": "2026-01-09T13:37:19.932655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load T5-XXL (what FLUX actually uses)\n",
    "t5_model_name = \"google/t5-v1_1-xxl\"  # 11GB, embedding_dim=4096\n",
    "t5_local_path = os.path.join(MODELS_DIR, \"google\", \"t5-v1_1-xxl\")\n",
    "\n",
    "print(f\"Loading T5 model: {t5_model_name}...\")\n",
    "print(f\"Local cache directory: {t5_local_path}\")\n",
    "print(\"This is a large model and will take several minutes to download on first run.\")\n",
    "print(\"Please be patient...\\n\")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(t5_local_path, exist_ok=True)\n",
    "\n",
    "# Load tokenizer and model - they will download to cache_dir if not already present\n",
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    t5_model_name,\n",
    "    cache_dir=MODELS_DIR\n",
    ")\n",
    "\n",
    "t5_model = T5EncoderModel.from_pretrained(\n",
    "    t5_model_name,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    cache_dir=MODELS_DIR\n",
    ").to(device)\n",
    "\n",
    "t5_model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(f\"\\n\u2713 T5-XXL loaded successfully!\")\n",
    "print(f\"  Embedding dimension: {t5_model.config.d_model}\")\n",
    "print(f\"  Max sequence length: {tokenizer.model_max_length}\")\n",
    "print(f\"  Model cached in: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load T5 Model (T5-XXL for FLUX)\n",
    "\n",
    "We'll use `google/t5-v1_1-xxl` which is what FLUX uses. This produces 4096-dimensional embeddings.\n",
    "\n",
    "**Note:** This is a large model (~11GB download). Make sure you have enough disk space and RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:47:51.064633Z",
     "iopub.status.busy": "2026-01-09T15:47:51.064400Z",
     "iopub.status.idle": "2026-01-09T15:49:16.087231Z",
     "shell.execute_reply": "2026-01-09T15:49:16.086376Z",
     "shell.execute_reply.started": "2026-01-09T15:47:51.064617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading T5 model: google/t5-v1_1-xxl...\n",
      "This is a large model and will take several minutes to download on first run.\n",
      "Please be patient...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u2713 T5-XXL loaded successfully!\n",
      "  Embedding dimension: 4096\n",
      "  Max sequence length: 512\n"
     ]
    }
   ],
   "source": [
    "# Load T5-XXL (what FLUX actually uses)\n",
    "t5_model_name = \"google/t5-v1_1-xxl\"  # 11GB, embedding_dim=4096\n",
    "\n",
    "print(f\"Loading T5 model: {t5_model_name}...\")\n",
    "print(\"This is a large model and will take several minutes to download on first run.\")\n",
    "print(\"Please be patient...\\n\")\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
    "t5_model = T5EncoderModel.from_pretrained(\n",
    "    t5_model_name,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ").to(device)\n",
    "t5_model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(f\"\\n\u2713 T5-XXL loaded successfully!\")\n",
    "print(f\"  Embedding dimension: {t5_model.config.d_model}\")\n",
    "print(f\"  Max sequence length: {tokenizer.model_max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Input Widget and Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:13:06.582240Z",
     "iopub.status.busy": "2026-01-06T13:13:06.582035Z",
     "iopub.status.idle": "2026-01-06T13:13:06.596018Z",
     "shell.execute_reply": "2026-01-06T13:13:06.595576Z",
     "shell.execute_reply.started": "2026-01-06T13:13:06.582223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3360a3f8af64e03ad53cab6916bd290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='a red cat sitting on a blue table', description='Prompt:', layout=Layout(height='80px', width=\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f21403b86184fb5a2b723901446cbb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Generate Embedding', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553f26f40f6344da8b5db19c52d7d94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create text input widget\n",
    "prompt_input = widgets.Textarea(\n",
    "    value='a red cat sitting on a blue table',\n",
    "    placeholder='Enter your prompt here',\n",
    "    description='Prompt:',\n",
    "    layout=widgets.Layout(width='80%', height='80px')\n",
    ")\n",
    "\n",
    "generate_button = widgets.Button(\n",
    "    description='Generate Embedding',\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Global variable to store current embedding\n",
    "current_embedding = None\n",
    "current_tokens = None\n",
    "\n",
    "def generate_embedding(b):\n",
    "    global current_embedding, current_tokens\n",
    "    \n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        \n",
    "        prompt = prompt_input.value\n",
    "        print(f\"Generating embedding for: '{prompt}'\\n\")\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = tokenizer(\n",
    "            prompt,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Get token strings for display\n",
    "        token_ids = tokens['input_ids'][0].tolist()\n",
    "        token_strings = [tokenizer.decode([tid]) for tid in token_ids]\n",
    "        \n",
    "        # Find how many real tokens (non-padding)\n",
    "        num_real_tokens = (tokens['input_ids'][0] != tokenizer.pad_token_id).sum().item()\n",
    "        \n",
    "        print(f\"Tokenized into {num_real_tokens} real tokens (+ {512 - num_real_tokens} padding):\")\n",
    "        print(\"First 10 tokens:\", token_strings[:10])\n",
    "        print()\n",
    "        \n",
    "        # Generate embedding\n",
    "        with torch.no_grad():\n",
    "            tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "            outputs = t5_model(**tokens)\n",
    "            embedding = outputs.last_hidden_state  # Shape: [1, 512, embedding_dim]\n",
    "        \n",
    "        current_embedding = embedding.cpu().numpy()[0]  # Shape: [512, embedding_dim]\n",
    "        current_tokens = token_strings\n",
    "        \n",
    "        embedding_dim = current_embedding.shape[1]\n",
    "        total_numbers = current_embedding.shape[0] * current_embedding.shape[1]\n",
    "        \n",
    "        print(f\"\u2713 Embedding generated!\")\n",
    "        print(f\"  Shape: {current_embedding.shape}\")\n",
    "        print(f\"  Total numbers: {total_numbers:,}\")\n",
    "        print(f\"  Size: {current_embedding.nbytes / 1024:.2f} KB\")\n",
    "        print()\n",
    "        print(f\"First token '{token_strings[0]}' embedding (first 10 values):\")\n",
    "        print(current_embedding[0, :10])\n",
    "\n",
    "generate_button.on_click(generate_embedding)\n",
    "\n",
    "display(prompt_input, generate_button, output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save Embedding to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:13:07.936560Z",
     "iopub.status.busy": "2026-01-06T13:13:07.936392Z",
     "iopub.status.idle": "2026-01-06T13:13:07.943512Z",
     "shell.execute_reply": "2026-01-06T13:13:07.943071Z",
     "shell.execute_reply.started": "2026-01-06T13:13:07.936546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c085d2e03b45bd913ff3484824a599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Save Embedding', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82bc5145a44461bb01b07b7299d8585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_embedding(filename=\"embedding.json\"):\n",
    "    if current_embedding is None:\n",
    "        print(\"\u274c No embedding to save! Generate one first.\")\n",
    "        return\n",
    "    \n",
    "    data = {\n",
    "        \"embedding\": current_embedding.tolist(),\n",
    "        \"tokens\": current_tokens,\n",
    "        \"shape\": list(current_embedding.shape),\n",
    "        \"prompt\": prompt_input.value\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    \n",
    "    file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "    print(f\"\u2713 Embedding saved to '{filename}' ({file_size:.2f} MB)\")\n",
    "\n",
    "# Save button\n",
    "save_button = widgets.Button(description='Save Embedding', button_style='info')\n",
    "save_output = widgets.Output()\n",
    "\n",
    "def on_save_click(b):\n",
    "    with save_output:\n",
    "        save_output.clear_output()\n",
    "        save_embedding()\n",
    "\n",
    "save_button.on_click(on_save_click)\n",
    "display(save_button, save_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Embedding from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:13:08.821036Z",
     "iopub.status.busy": "2026-01-06T13:13:08.820858Z",
     "iopub.status.idle": "2026-01-06T13:13:08.828697Z",
     "shell.execute_reply": "2026-01-06T13:13:08.828272Z",
     "shell.execute_reply.started": "2026-01-06T13:13:08.821021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c276b83d24564e75be0d0730b236a23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Load Embedding', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2397f321ccd441a8ac8bd5eef34d0b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_embedding(filename=\"embedding.json\"):\n",
    "    global current_embedding, current_tokens\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    current_embedding = np.array(data['embedding'])\n",
    "    current_tokens = data['tokens']\n",
    "    \n",
    "    print(f\"\u2713 Embedding loaded from '{filename}'\")\n",
    "    print(f\"  Original prompt: {data['prompt']}\")\n",
    "    print(f\"  Shape: {current_embedding.shape}\")\n",
    "    print(f\"  First token: '{current_tokens[0]}'\")\n",
    "\n",
    "# Load button\n",
    "load_button = widgets.Button(description='Load Embedding', button_style='warning')\n",
    "load_output = widgets.Output()\n",
    "\n",
    "def on_load_click(b):\n",
    "    with load_output:\n",
    "        load_output.clear_output()\n",
    "        try:\n",
    "            load_embedding()\n",
    "        except FileNotFoundError:\n",
    "            print(\"\u274c File 'embedding.json' not found. Save an embedding first.\")\n",
    "\n",
    "load_button.on_click(on_load_click)\n",
    "display(load_button, load_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Manual Embedding Manipulation\n",
    "\n",
    "Example: Zero out a percentage of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:13:33.043325Z",
     "iopub.status.busy": "2026-01-06T13:13:33.043121Z",
     "iopub.status.idle": "2026-01-06T13:13:33.053027Z",
     "shell.execute_reply": "2026-01-06T13:13:33.052534Z",
     "shell.execute_reply.started": "2026-01-06T13:13:33.043310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcc1feecb574113bdc249911c6c873b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.3, description='Zero %:', max=1.0, readout_format='.0%', step=0.05)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e763ed817340548d62bfcc2baffdef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Apply Manipulation', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b8220c16b64e2a964f9135c0adc4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def manipulate_embedding(zero_percentage=0.3):\n",
    "    global current_embedding\n",
    "    \n",
    "    if current_embedding is None:\n",
    "        print(\"\u274c No embedding loaded!\")\n",
    "        return\n",
    "    \n",
    "    # Create a copy\n",
    "    modified = current_embedding.copy()\n",
    "    \n",
    "    # Randomly zero out a percentage of values\n",
    "    total_values = modified.size\n",
    "    num_zeros = int(total_values * zero_percentage)\n",
    "    \n",
    "    # Random indices\n",
    "    flat_modified = modified.flatten()\n",
    "    zero_indices = np.random.choice(total_values, num_zeros, replace=False)\n",
    "    flat_modified[zero_indices] = 0.0\n",
    "    \n",
    "    modified = flat_modified.reshape(current_embedding.shape)\n",
    "    \n",
    "    print(f\"\u2713 Zeroed out {num_zeros:,} values ({zero_percentage*100}%)\")\n",
    "    print(f\"  Original non-zero: {np.count_nonzero(current_embedding):,}\")\n",
    "    print(f\"  Modified non-zero: {np.count_nonzero(modified):,}\")\n",
    "    \n",
    "    return modified\n",
    "\n",
    "# Manipulation widget\n",
    "zero_slider = widgets.FloatSlider(\n",
    "    value=0.3,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Zero %:',\n",
    "    readout_format='.0%'\n",
    ")\n",
    "\n",
    "manipulate_button = widgets.Button(description='Apply Manipulation', button_style='danger')\n",
    "manipulate_output = widgets.Output()\n",
    "\n",
    "modified_embedding = None\n",
    "\n",
    "def on_manipulate_click(b):\n",
    "    global modified_embedding\n",
    "    with manipulate_output:\n",
    "        manipulate_output.clear_output()\n",
    "        modified_embedding = manipulate_embedding(zero_slider.value)\n",
    "\n",
    "manipulate_button.on_click(on_manipulate_click)\n",
    "display(zero_slider, manipulate_button, manipulate_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Manual Attention Masking\n",
    "\n",
    "Control which tokens get how much attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:13:37.324136Z",
     "iopub.status.busy": "2026-01-06T13:13:37.323956Z",
     "iopub.status.idle": "2026-01-06T13:13:37.342167Z",
     "shell.execute_reply": "2026-01-06T13:13:37.341657Z",
     "shell.execute_reply.started": "2026-01-06T13:13:37.324122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sliders for first 8 tokens:\n",
      "[(1, 'a'), (2, 'red'), (3, 'cat'), (4, 'sitting'), (5, 'on'), (7, 'a'), (8, 'blue'), (9, 'table')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df10b32a53e4da69297ae24a2c84cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=0.125, description='1: a', layout=Layout(width='400px'), max=1.0, readout_for\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display tokens and create sliders\n",
    "def create_attention_sliders(num_tokens=10):\n",
    "    if current_tokens is None:\n",
    "        print(\"\u274c Generate an embedding first!\")\n",
    "        return None\n",
    "    \n",
    "    # Find non-padding tokens\n",
    "    real_tokens = []\n",
    "    for i, token in enumerate(current_tokens):\n",
    "        if token.strip() and token != '<pad>' and i < num_tokens:\n",
    "            real_tokens.append((i, token))\n",
    "    \n",
    "    print(f\"Creating sliders for first {len(real_tokens)} tokens:\")\n",
    "    print(real_tokens)\n",
    "    print()\n",
    "    \n",
    "    sliders = []\n",
    "    for idx, token in real_tokens:\n",
    "        slider = widgets.FloatSlider(\n",
    "            value=1.0 / len(real_tokens),  # Equal distribution\n",
    "            min=0.0,\n",
    "            max=1.0,\n",
    "            step=0.01,\n",
    "            description=f'{idx}: {token[:15]}',\n",
    "            readout_format='.0%',\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        sliders.append(slider)\n",
    "    \n",
    "    # Normalize button\n",
    "    normalize_button = widgets.Button(\n",
    "        description='Normalize to 100%',\n",
    "        button_style='info'\n",
    "    )\n",
    "    \n",
    "    total_label = widgets.Label(value='Total: 100%')\n",
    "    \n",
    "    def update_total(*args):\n",
    "        total = sum(s.value for s in sliders)\n",
    "        total_label.value = f'Total: {total*100:.1f}%'\n",
    "        if abs(total - 1.0) > 0.01:\n",
    "            total_label.value += ' \u26a0\ufe0f Should sum to 100%'\n",
    "    \n",
    "    def normalize(*args):\n",
    "        total = sum(s.value for s in sliders)\n",
    "        if total > 0:\n",
    "            for s in sliders:\n",
    "                s.value = s.value / total\n",
    "        update_total()\n",
    "    \n",
    "    for slider in sliders:\n",
    "        slider.observe(update_total, 'value')\n",
    "    \n",
    "    normalize_button.on_click(normalize)\n",
    "    \n",
    "    update_total()\n",
    "    \n",
    "    return sliders, normalize_button, total_label, real_tokens\n",
    "\n",
    "attention_controls = create_attention_sliders(num_tokens=10)\n",
    "\n",
    "if attention_controls:\n",
    "    sliders, normalize_btn, total_lbl, real_tokens = attention_controls\n",
    "    display(widgets.VBox(sliders + [normalize_btn, total_lbl]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Attention Mask Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:13:41.518851Z",
     "iopub.status.busy": "2026-01-06T13:13:41.518697Z",
     "iopub.status.idle": "2026-01-06T13:13:41.526395Z",
     "shell.execute_reply": "2026-01-06T13:13:41.525715Z",
     "shell.execute_reply.started": "2026-01-06T13:13:41.518837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780f29cf780f4fa28bc8b381b1fc6fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Create Mask', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25ee3d9673546448435fda9f64632cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_attention_mask():\n",
    "    if attention_controls is None:\n",
    "        print(\"\u274c Create attention sliders first!\")\n",
    "        return None\n",
    "    \n",
    "    sliders, _, _, real_tokens = attention_controls\n",
    "    \n",
    "    # Create mask array (512 tokens)\n",
    "    mask = np.zeros(512)\n",
    "    \n",
    "    # Set weights from sliders\n",
    "    for slider, (idx, token) in zip(sliders, real_tokens):\n",
    "        mask[idx] = slider.value\n",
    "    \n",
    "    print(\"Attention Mask created:\")\n",
    "    print(f\"Non-zero weights: {np.count_nonzero(mask)}\")\n",
    "    for slider, (idx, token) in zip(sliders, real_tokens):\n",
    "        print(f\"  Token {idx} '{token}': {slider.value*100:.1f}%\")\n",
    "    \n",
    "    return mask\n",
    "\n",
    "mask_button = widgets.Button(description='Create Mask', button_style='success')\n",
    "mask_output = widgets.Output()\n",
    "\n",
    "attention_mask = None\n",
    "\n",
    "def on_mask_click(b):\n",
    "    global attention_mask\n",
    "    with mask_output:\n",
    "        mask_output.clear_output()\n",
    "        attention_mask = create_attention_mask()\n",
    "\n",
    "mask_button.on_click(on_mask_click)\n",
    "display(mask_button, mask_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load FLUX Model\n",
    "\n",
    "**Warning:** FLUX-schnell is still large (~24GB). This will take time and require significant VRAM/RAM.\n",
    "\n",
    "If you don't have enough resources, skip this section and the embedding/mask experiments above are still valuable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:13:43.000660Z",
     "iopub.status.busy": "2026-01-06T13:13:43.000458Z",
     "iopub.status.idle": "2026-01-06T13:16:43.767210Z",
     "shell.execute_reply": "2026-01-06T13:16:43.766568Z",
     "shell.execute_reply.started": "2026-01-06T13:13:43.000645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FLUX-schnell from local folder...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288342c4a6e04283b7655ecafadbced2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d8dde69aa141f6a9bfad3c478c51c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae07e5a44e5469a8bf19ef8ce2d7186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 FLUX loaded successfully from local folder!\n"
     ]
    }
   ],
   "source": [
    "# FLUX Model Path\n",
    "flux_model_name = \"black-forest-labs/FLUX.1-dev\"\n",
    "flux_local_path = os.path.join(MODELS_DIR, \"black-forest-labs\", \"FLUX.1-dev\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING FLUX MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {flux_model_name}\")\n",
    "print(f\"Local cache directory: {flux_local_path}\")\n",
    "print(\"\\nThis is a very large model (~24GB).\")\n",
    "print(\"First-time download will take 20-60 minutes depending on connection.\")\n",
    "print(\"Subsequent loads will be much faster using cached files.\")\n",
    "print(\"\\nLoading...\\n\")\n",
    "\n",
    "try:\n",
    "    # Create directory\n",
    "    os.makedirs(flux_local_path, exist_ok=True)\n",
    "    \n",
    "    # Load FLUX pipeline - will download to cache_dir if not present\n",
    "    flux_pipe = FluxPipeline.from_pretrained(\n",
    "        flux_model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        cache_dir=MODELS_DIR\n",
    "    )\n",
    "    flux_pipe = flux_pipe.to(device)\n",
    "    print(\"\u2713 FLUX loaded successfully!\")\n",
    "    print(f\"  Model cached in: {MODELS_DIR}\")\n",
    "    print(\"  Device:\", device)\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error loading FLUX: {e}\")\n",
    "    print(\"\\nPlease check that:\")\n",
    "    print(\"1. You have enough disk space (~24GB for FLUX)\")\n",
    "    print(\"2. You have enough RAM/VRAM to load the model\")\n",
    "    print(\"3. Your internet connection is stable (for first-time download)\")\n",
    "    print(\"\\nYou may need to authenticate with Hugging Face:\")\n",
    "    print(\"  Run: huggingface-cli login\")\n",
    "    print(\"  Or set: export HF_TOKEN=your_token_here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Image from Loaded Embedding\n",
    "\n",
    "This will use the embedding loaded from the JSON file to generate an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:16:43.768404Z",
     "iopub.status.busy": "2026-01-06T13:16:43.767840Z",
     "iopub.status.idle": "2026-01-06T13:16:43.783419Z",
     "shell.execute_reply": "2026-01-06T13:16:43.782930Z",
     "shell.execute_reply.started": "2026-01-06T13:16:43.768388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29dec60e7f604c869b9bab0f379414f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Generate Images from Embeddings</h3>'), Button(button_style='primary', descript\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7587a56a3e4a68a7eaa02da0a1b045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_image_from_embedding(embedding_array, output_filename=\"generated_from_embedding.png\", seed=42):\n",
    "    \"\"\"\n",
    "    Generate image using custom T5 embedding by injecting it into FLUX pipeline.\n",
    "    \"\"\"\n",
    "    if 'flux_pipe' not in globals():\n",
    "        print(\"\u274c FLUX not loaded!\")\n",
    "        return None\n",
    "    \n",
    "    if embedding_array is None:\n",
    "        print(\"\u274c No embedding provided! Load an embedding first.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Generating image from custom embedding...\")\n",
    "    print(f\"  Embedding shape: {embedding_array.shape}\")\n",
    "    print(f\"  Expected shape: [512, 4096]\")\n",
    "    \n",
    "    # Convert numpy to torch tensor\n",
    "    embedding_tensor = torch.from_numpy(embedding_array).to(\n",
    "        device=device,\n",
    "        dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    "    )\n",
    "    \n",
    "    # Add batch dimension: [512, 4096] -> [1, 512, 4096]\n",
    "    embedding_tensor = embedding_tensor.unsqueeze(0)\n",
    "    \n",
    "    print(f\"  Tensor shape: {embedding_tensor.shape}\")\n",
    "    print(f\"  Device: {embedding_tensor.device}\")\n",
    "    print(f\"  Dtype: {embedding_tensor.dtype}\")\n",
    "    print()\n",
    "    \n",
    "    # Generate image using the custom embedding\n",
    "    # We'll inject this into the pipeline by using prompt_embeds parameter\n",
    "    try:\n",
    "        print(\"Running diffusion process (4 steps)...\")\n",
    "        image = flux_pipe(\n",
    "            prompt_embeds=embedding_tensor,\n",
    "            num_inference_steps=4,\n",
    "            guidance_scale=0.0,\n",
    "            height=1024,\n",
    "            width=1024,\n",
    "            generator=torch.manual_seed(seed)\n",
    "        ).images[0]\n",
    "        \n",
    "        image.save(output_filename)\n",
    "        print(f\"\\n\u2713 Image generated and saved to '{output_filename}'\")\n",
    "        \n",
    "        return image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error generating image: {e}\")\n",
    "        print(\"\\nThis might happen if:\")\n",
    "        print(\"  - Embedding dimensions don't match (should be [1, 512, 4096])\")\n",
    "        print(\"  - FLUX version doesn't support prompt_embeds parameter\")\n",
    "        print(\"  - Insufficient VRAM/RAM\")\n",
    "        return None\n",
    "\n",
    "# Generate from current embedding button\n",
    "generate_from_embedding_button = widgets.Button(\n",
    "    description='Generate from Current Embedding',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "# Generate from modified embedding button\n",
    "generate_from_modified_button = widgets.Button(\n",
    "    description='Generate from Modified Embedding',\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "generation_output = widgets.Output()\n",
    "\n",
    "def on_generate_from_embedding(b):\n",
    "    with generation_output:\n",
    "        generation_output.clear_output(wait=True)\n",
    "        if current_embedding is not None:\n",
    "            image = generate_image_from_embedding(\n",
    "                current_embedding,\n",
    "                output_filename=\"image_original_embedding.png\"\n",
    "            )\n",
    "            if image:\n",
    "                display(image)\n",
    "        else:\n",
    "            print(\"\u274c No embedding loaded! Generate or load an embedding first.\")\n",
    "\n",
    "def on_generate_from_modified(b):\n",
    "    with generation_output:\n",
    "        generation_output.clear_output(wait=True)\n",
    "        if modified_embedding is not None:\n",
    "            image = generate_image_from_embedding(\n",
    "                modified_embedding,\n",
    "                output_filename=\"image_modified_embedding.png\"\n",
    "            )\n",
    "            if image:\n",
    "                display(image)\n",
    "        else:\n",
    "            print(\"\u274c No modified embedding! Apply a manipulation first.\")\n",
    "\n",
    "generate_from_embedding_button.on_click(on_generate_from_embedding)\n",
    "generate_from_modified_button.on_click(on_generate_from_modified)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Generate Images from Embeddings</h3>\"),\n",
    "    generate_from_embedding_button,\n",
    "    generate_from_modified_button\n",
    "]), generation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare Original vs Modified Embeddings\n",
    "\n",
    "Generate both images and view them side-by-side to see the effect of your modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:16:43.783867Z",
     "iopub.status.busy": "2026-01-06T13:16:43.783735Z",
     "iopub.status.idle": "2026-01-06T13:16:43.854072Z",
     "shell.execute_reply": "2026-01-06T13:16:43.853588Z",
     "shell.execute_reply.started": "2026-01-06T13:16:43.783855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f57ef059f2b44e2ae277ef8cca98b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>\u26a1 Generate Comparison</h3><p>This will generate images from both embeddings wit\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693f70ecb6264e9183d7e006d5fdc069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_embeddings(seed=42):\n",
    "    \"\"\"\n",
    "    Generate images from both original and modified embeddings and display side-by-side.\n",
    "    \"\"\"\n",
    "    if 'flux_pipe' not in globals():\n",
    "        print(\"\u274c FLUX not loaded!\")\n",
    "        return\n",
    "    \n",
    "    if current_embedding is None:\n",
    "        print(\"\u274c No original embedding! Generate or load an embedding first.\")\n",
    "        return\n",
    "    \n",
    "    if modified_embedding is None:\n",
    "        print(\"\u274c No modified embedding! Apply a manipulation first.\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"EMBEDDING COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Show embedding statistics\n",
    "    print(\"\\nORIGINAL EMBEDDING:\")\n",
    "    print(f\"  Non-zero values: {np.count_nonzero(current_embedding):,}\")\n",
    "    print(f\"  Mean: {current_embedding.mean():.4f}\")\n",
    "    print(f\"  Std: {current_embedding.std():.4f}\")\n",
    "    print(f\"  Min: {current_embedding.min():.4f}\")\n",
    "    print(f\"  Max: {current_embedding.max():.4f}\")\n",
    "    \n",
    "    print(\"\\nMODIFIED EMBEDDING:\")\n",
    "    print(f\"  Non-zero values: {np.count_nonzero(modified_embedding):,}\")\n",
    "    print(f\"  Mean: {modified_embedding.mean():.4f}\")\n",
    "    print(f\"  Std: {modified_embedding.std():.4f}\")\n",
    "    print(f\"  Min: {modified_embedding.min():.4f}\")\n",
    "    print(f\"  Max: {modified_embedding.max():.4f}\")\n",
    "    \n",
    "    diff = np.abs(current_embedding - modified_embedding).sum()\n",
    "    print(f\"\\nTOTAL ABSOLUTE DIFFERENCE: {diff:,.2f}\")\n",
    "    print(f\"Percentage changed: {(np.count_nonzero(current_embedding != modified_embedding) / current_embedding.size * 100):.2f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENERATING IMAGES...\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Generate from original\n",
    "    print(\"[1/2] Generating from ORIGINAL embedding...\")\n",
    "    img1 = generate_image_from_embedding(\n",
    "        current_embedding,\n",
    "        output_filename=\"comparison_original.png\",\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    if img1 is None:\n",
    "        return\n",
    "    \n",
    "    print(\"\\n[2/2] Generating from MODIFIED embedding...\")\n",
    "    img2 = generate_image_from_embedding(\n",
    "        modified_embedding,\n",
    "        output_filename=\"comparison_modified.png\",\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    if img2 is None:\n",
    "        return\n",
    "    \n",
    "    # Display side by side\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPARISON RESULTS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    axes[0].imshow(img1)\n",
    "    axes[0].set_title('Original Embedding', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(img2)\n",
    "    axes[1].set_title('Modified Embedding', fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Prompt: \"{prompt_input.value}\"', fontsize=12, y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"comparison_sidebyside.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\u2713 Comparison complete!\")\n",
    "    print(\"\\nFiles saved:\")\n",
    "    print(\"  - comparison_original.png\")\n",
    "    print(\"  - comparison_modified.png\")\n",
    "    print(\"  - comparison_sidebyside.png\")\n",
    "\n",
    "# Comparison button\n",
    "compare_button = widgets.Button(\n",
    "    description='Compare Original vs Modified',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='300px', height='50px')\n",
    ")\n",
    "\n",
    "compare_output = widgets.Output()\n",
    "\n",
    "def on_compare_click(b):\n",
    "    with compare_output:\n",
    "        compare_output.clear_output(wait=True)\n",
    "        compare_embeddings()\n",
    "\n",
    "compare_button.on_click(on_compare_click)\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>\u26a1 Generate Comparison</h3><p>This will generate images from both embeddings with the same random seed.</p>\"),\n",
    "    compare_button\n",
    "]), compare_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "What you've learned:\n",
    "\n",
    "1. \u2713 Generate T5-XXL embeddings from text (512 tokens \u00d7 4096 dimensions = 2,097,152 numbers)\n",
    "2. \u2713 Save/load embeddings as JSON files\n",
    "3. \u2713 Manually manipulate embedding values\n",
    "4. \u2713 Create custom attention masks with sliders\n",
    "5. \u2713 Generate images directly from custom embeddings using FLUX\n",
    "6. \u2713 Compare original vs modified embeddings side-by-side\n",
    "7. \u2713 Understand the complete pipeline: text \u2192 T5-XXL \u2192 embeddings \u2192 FLUX \u2192 image\n",
    "\n",
    "## Workflow:\n",
    "\n",
    "1. **Generate embedding** from your text prompt\n",
    "2. **Save to JSON** for backup\n",
    "3. **Apply manipulations** (zero out values, etc.)\n",
    "4. **Create attention masks** (optional - for future use)\n",
    "5. **Generate images** from both original and modified embeddings\n",
    "6. **Compare results** to see what your changes did!\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "- Experiment with different zero percentages (10%, 30%, 50%, 90%)\n",
    "- Try zeroing specific token embeddings instead of random values\n",
    "- Compare results with different prompts\n",
    "- Implement attention mask injection (requires modifying cross-attention layers)\n",
    "- Explore interpolating between two different embeddings\n",
    "- Try adding noise to embeddings and see the effect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flux uv",
   "language": "python",
   "name": "uv_flux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}