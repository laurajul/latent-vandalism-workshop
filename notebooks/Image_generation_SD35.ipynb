{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 & CLIP Embedding Manipulation for Stable Diffusion 3.5\n",
    "\n",
    "This notebook lets you:\n",
    "1. Generate T5 and CLIP embeddings from text prompts\n",
    "2. Save/load embeddings as JSON\n",
    "3. Select positive AND negative embeddings for both T5 and CLIP\n",
    "4. Control guidance scale\n",
    "5. Generate images with SD 3.5 using modified embeddings\n",
    "6. Compare with FLUX results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from diffusers import StableDiffusion3Pipeline\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image as IPImage\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create models directory\n",
    "current_dir = Path.cwd()\n",
    "MODELS_DIR = current_dir.parent / \"data/models\"\n",
    "SD35_MODEL_PATH = os.path.join(MODELS_DIR, \"stable-diffusion-3.5-large\")\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "print(f\"Models directory: {os.path.abspath(MODELS_DIR)}\")\n",
    "print(f\"SD 3.5 path: {os.path.abspath(SD35_MODEL_PATH)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Stable Diffusion 3.5 from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Hugging Face token from file\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the token file path\n",
    "current_dir = Path.cwd()\n",
    "token_file = current_dir.parent / \"misc/credentials/hf.txt\"\n",
    "\n",
    "print(f\"Looking for HF token at: {token_file}\")\n",
    "\n",
    "if token_file.exists():\n",
    "    with open(token_file, 'r') as f:\n",
    "        hf_token = f.read().strip()\n",
    "    \n",
    "    # Set the token as an environment variable\n",
    "    os.environ['HF_TOKEN'] = hf_token\n",
    "    \n",
    "    # Also login using huggingface_hub\n",
    "    from huggingface_hub import login\n",
    "    login(token=hf_token)\n",
    "    print(\"✓ Logged in to Hugging Face\")\n",
    "else:\n",
    "    print(\"⚠️ No HF token found - you may need to authenticate manually\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Stable Diffusion 3.5\n",
    "try:\n",
    "    if not os.path.exists(SD35_MODEL_PATH):\n",
    "        print(\"Downloading Stable Diffusion 3.5 Large from Hugging Face...\")\n",
    "        sd_pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "            \"stabilityai/stable-diffusion-3.5-large\",\n",
    "            torch_dtype=torch.bfloat16\n",
    "        )\n",
    "        sd_pipe.save_pretrained(SD35_MODEL_PATH)\n",
    "        print(f\"✓ Model downloaded and saved to {SD35_MODEL_PATH}\")\n",
    "    else:\n",
    "        print(\"Loading Stable Diffusion 3.5 from local path...\")\n",
    "        sd_pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "            SD35_MODEL_PATH,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            local_files_only=True\n",
    "        )\n",
    "    \n",
    "    sd_pipe = sd_pipe.to(device)\n",
    "    print(\"✓ Stable Diffusion 3.5 loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading SD 3.5: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings Interface\n",
    "\n",
    "Select **positive** and **negative** embeddings for both T5 and CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories\n",
    "T5_EMBEDDINGS_DIR = current_dir.parent / \"data/embeddings/T5\"\n",
    "CLIP_EMBEDDINGS_DIR = current_dir.parent / \"data/embeddings/CLIP\"\n",
    "\n",
    "# Global variables for loaded embeddings\n",
    "loaded_t5_pos_embedding = None\n",
    "loaded_t5_neg_embedding = None\n",
    "loaded_clip_pos_embedding = None\n",
    "loaded_clip_neg_embedding = None\n",
    "\n",
    "loaded_t5_pos_prompt = None\n",
    "loaded_t5_neg_prompt = None\n",
    "loaded_clip_pos_prompt = None\n",
    "loaded_clip_neg_prompt = None\n",
    "\n",
    "# Get available embedding files\n",
    "t5_files = []\n",
    "clip_files = []\n",
    "\n",
    "if T5_EMBEDDINGS_DIR.exists():\n",
    "    t5_files = sorted([f.name for f in T5_EMBEDDINGS_DIR.glob('*.json')])\n",
    "\n",
    "if CLIP_EMBEDDINGS_DIR.exists():\n",
    "    clip_files = sorted([f.name for f in CLIP_EMBEDDINGS_DIR.glob('*.json')])\n",
    "\n",
    "# Add 'None' option for negative embeddings\n",
    "t5_files_with_none = ['(None)'] + t5_files\n",
    "clip_files_with_none = ['(None)'] + clip_files\n",
    "\n",
    "print(f\"Found {len(t5_files)} T5 embeddings\")\n",
    "print(f\"Found {len(clip_files)} CLIP embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5 Embeddings Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5 POSITIVE embedding selection\n",
    "t5_pos_dropdown = widgets.Dropdown(\n",
    "    options=t5_files,\n",
    "    description='T5 Positive:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='600px')\n",
    ")\n",
    "\n",
    "load_t5_pos_button = widgets.Button(\n",
    "    description='Load T5 Positive',\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "t5_pos_output = widgets.Output()\n",
    "\n",
    "# T5 NEGATIVE embedding selection\n",
    "t5_neg_dropdown = widgets.Dropdown(\n",
    "    options=t5_files_with_none,\n",
    "    description='T5 Negative:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='600px')\n",
    ")\n",
    "\n",
    "load_t5_neg_button = widgets.Button(\n",
    "    description='Load T5 Negative',\n",
    "    button_style='warning'\n",
    ")\n",
    "\n",
    "t5_neg_output = widgets.Output()\n",
    "\n",
    "def load_t5_pos_embedding(b):\n",
    "    global loaded_t5_pos_embedding, loaded_t5_pos_prompt\n",
    "    \n",
    "    with t5_pos_output:\n",
    "        t5_pos_output.clear_output()\n",
    "        \n",
    "        filename = t5_pos_dropdown.value\n",
    "        if not filename:\n",
    "            print(\"❌ No file selected!\")\n",
    "            return\n",
    "        \n",
    "        filepath = T5_EMBEDDINGS_DIR / filename\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            loaded_t5_pos_embedding = np.array(data['embedding'])\n",
    "            loaded_t5_pos_prompt = data.get('prompt', 'Unknown')\n",
    "            \n",
    "            print(f\"✓ Loaded T5 POSITIVE embedding!\")\n",
    "            print(f\"  File: {filename}\")\n",
    "            print(f\"  Prompt: '{loaded_t5_pos_prompt}'\")\n",
    "            print(f\"  Shape: {loaded_t5_pos_embedding.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading T5 positive embedding: {e}\")\n",
    "\n",
    "def load_t5_neg_embedding(b):\n",
    "    global loaded_t5_neg_embedding, loaded_t5_neg_prompt\n",
    "    \n",
    "    with t5_neg_output:\n",
    "        t5_neg_output.clear_output()\n",
    "        \n",
    "        filename = t5_neg_dropdown.value\n",
    "        if not filename or filename == '(None)':\n",
    "            loaded_t5_neg_embedding = None\n",
    "            loaded_t5_neg_prompt = None\n",
    "            print(\"✓ No negative T5 embedding (will use default)\")\n",
    "            return\n",
    "        \n",
    "        filepath = T5_EMBEDDINGS_DIR / filename\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            loaded_t5_neg_embedding = np.array(data['embedding'])\n",
    "            loaded_t5_neg_prompt = data.get('prompt', 'Unknown')\n",
    "            \n",
    "            print(f\"✓ Loaded T5 NEGATIVE embedding!\")\n",
    "            print(f\"  File: {filename}\")\n",
    "            print(f\"  Prompt: '{loaded_t5_neg_prompt}'\")\n",
    "            print(f\"  Shape: {loaded_t5_neg_embedding.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading T5 negative embedding: {e}\")\n",
    "\n",
    "load_t5_pos_button.on_click(load_t5_pos_embedding)\n",
    "load_t5_neg_button.on_click(load_t5_neg_embedding)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>1. T5 Embeddings</h3>\"),\n",
    "    widgets.HTML(\"<b>Positive Embedding:</b>\"),\n",
    "    t5_pos_dropdown,\n",
    "    load_t5_pos_button,\n",
    "    t5_pos_output,\n",
    "    widgets.HTML(\"<br><b>Negative Embedding (optional):</b>\"),\n",
    "    t5_neg_dropdown,\n",
    "    load_t5_neg_button,\n",
    "    t5_neg_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP Embeddings Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIP POSITIVE embedding selection\n",
    "clip_pos_dropdown = widgets.Dropdown(\n",
    "    options=clip_files,\n",
    "    description='CLIP Positive:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='600px')\n",
    ")\n",
    "\n",
    "load_clip_pos_button = widgets.Button(\n",
    "    description='Load CLIP Positive',\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "clip_pos_output = widgets.Output()\n",
    "\n",
    "# CLIP NEGATIVE embedding selection\n",
    "clip_neg_dropdown = widgets.Dropdown(\n",
    "    options=clip_files_with_none,\n",
    "    description='CLIP Negative:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='600px')\n",
    ")\n",
    "\n",
    "load_clip_neg_button = widgets.Button(\n",
    "    description='Load CLIP Negative',\n",
    "    button_style='warning'\n",
    ")\n",
    "\n",
    "clip_neg_output = widgets.Output()\n",
    "\n",
    "def load_clip_pos_embedding(b):\n",
    "    global loaded_clip_pos_embedding, loaded_clip_pos_prompt\n",
    "    \n",
    "    with clip_pos_output:\n",
    "        clip_pos_output.clear_output()\n",
    "        \n",
    "        filename = clip_pos_dropdown.value\n",
    "        if not filename:\n",
    "            print(\"❌ No file selected!\")\n",
    "            return\n",
    "        \n",
    "        filepath = CLIP_EMBEDDINGS_DIR / filename\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            loaded_clip_pos_embedding = np.array(data['embedding'])\n",
    "            loaded_clip_pos_prompt = data.get('prompt', 'Unknown')\n",
    "            \n",
    "            print(f\"✓ Loaded CLIP POSITIVE embedding!\")\n",
    "            print(f\"  File: {filename}\")\n",
    "            print(f\"  Prompt: '{loaded_clip_pos_prompt}'\")\n",
    "            print(f\"  Shape: {loaded_clip_pos_embedding.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading CLIP positive embedding: {e}\")\n",
    "\n",
    "def load_clip_neg_embedding(b):\n",
    "    global loaded_clip_neg_embedding, loaded_clip_neg_prompt\n",
    "    \n",
    "    with clip_neg_output:\n",
    "        clip_neg_output.clear_output()\n",
    "        \n",
    "        filename = clip_neg_dropdown.value\n",
    "        if not filename or filename == '(None)':\n",
    "            loaded_clip_neg_embedding = None\n",
    "            loaded_clip_neg_prompt = None\n",
    "            print(\"✓ No negative CLIP embedding (will use default)\")\n",
    "            return\n",
    "        \n",
    "        filepath = CLIP_EMBEDDINGS_DIR / filename\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            loaded_clip_neg_embedding = np.array(data['embedding'])\n",
    "            loaded_clip_neg_prompt = data.get('prompt', 'Unknown')\n",
    "            \n",
    "            print(f\"✓ Loaded CLIP NEGATIVE embedding!\")\n",
    "            print(f\"  File: {filename}\")\n",
    "            print(f\"  Prompt: '{loaded_clip_neg_prompt}'\")\n",
    "            print(f\"  Shape: {loaded_clip_neg_embedding.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading CLIP negative embedding: {e}\")\n",
    "\n",
    "load_clip_pos_button.on_click(load_clip_pos_embedding)\n",
    "load_clip_neg_button.on_click(load_clip_neg_embedding)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    widgets.HTML(\"<h3>2. CLIP Embeddings</h3>\"),\n",
    "    widgets.HTML(\"<b>Positive Embedding:</b>\"),\n",
    "    clip_pos_dropdown,\n",
    "    load_clip_pos_button,\n",
    "    clip_pos_output,\n",
    "    widgets.HTML(\"<br><b>Negative Embedding (optional):</b>\"),\n",
    "    clip_neg_dropdown,\n",
    "    load_clip_neg_button,\n",
    "    clip_neg_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Image with Positive and Negative Embeddings\n",
    "\n",
    "Control guidance scale to balance between positive and negative embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output directory\n",
    "OUTPUT_IMAGES_DIR = current_dir.parent / \"output/images/SD35\"\n",
    "os.makedirs(OUTPUT_IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "def parse_embedding_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse embedding filename to extract tokens and manipulation.\n",
    "    Returns (tokens_string, manipulation_string)\n",
    "    \"\"\"\n",
    "    if not filename or filename == '(None)':\n",
    "        return ('none', '')\n",
    "    \n",
    "    # Remove .json extension\n",
    "    base_name = filename.rsplit('.', 1)[0]\n",
    "    \n",
    "    # Split by underscore\n",
    "    parts = base_name.split('_')\n",
    "    \n",
    "    # First 4 parts are the tokens - join without underscores\n",
    "    if len(parts) <= 4:\n",
    "        tokens = ''.join(parts)\n",
    "        return (tokens, '')\n",
    "    \n",
    "    tokens = ''.join(parts[:4])\n",
    "    \n",
    "    # Get manipulation type (simplified)\n",
    "    manipulation_parts = parts[4:]\n",
    "    if manipulation_parts:\n",
    "        manipulation = manipulation_parts[0]\n",
    "    else:\n",
    "        manipulation = ''\n",
    "    \n",
    "    return (tokens, manipulation)\n",
    "\n",
    "def generate_from_loaded_embeddings(seed=42, guidance_scale=7.0):\n",
    "    \"\"\"\n",
    "    Generate image using loaded positive and negative T5/CLIP embeddings.\n",
    "    \"\"\"\n",
    "    if 'sd_pipe' not in globals():\n",
    "        print(\"❌ SD 3.5 pipeline not loaded!\")\n",
    "        return None\n",
    "    \n",
    "    if loaded_t5_pos_embedding is None:\n",
    "        print(\"❌ No positive T5 embedding loaded! Load a T5 positive embedding first.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Generating image from loaded embeddings...\")\n",
    "    print(f\"  Guidance scale: {guidance_scale}\")\n",
    "    print()\n",
    "    \n",
    "    # Process POSITIVE T5 embedding\n",
    "    print(\"POSITIVE T5:\")\n",
    "    print(f\"  Shape: {loaded_t5_pos_embedding.shape}\")\n",
    "    print(f\"  Prompt: '{loaded_t5_pos_prompt}'\")\n",
    "    \n",
    "    t5_pos_tensor = torch.from_numpy(loaded_t5_pos_embedding.astype(np.float32)).to(\n",
    "        device=device,\n",
    "        dtype=torch.bfloat16\n",
    "    ).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Process NEGATIVE T5 embedding\n",
    "    if loaded_t5_neg_embedding is not None:\n",
    "        print(\"\\nNEGATIVE T5:\")\n",
    "        print(f\"  Shape: {loaded_t5_neg_embedding.shape}\")\n",
    "        print(f\"  Prompt: '{loaded_t5_neg_prompt}'\")\n",
    "        \n",
    "        t5_neg_tensor = torch.from_numpy(loaded_t5_neg_embedding.astype(np.float32)).to(\n",
    "            device=device,\n",
    "            dtype=torch.bfloat16\n",
    "        ).unsqueeze(0)\n",
    "    else:\n",
    "        print(\"\\nNEGATIVE T5: Using default (empty)\")\n",
    "        t5_neg_tensor = None\n",
    "    \n",
    "    # Process POSITIVE CLIP embedding\n",
    "    print(\"\\nPOSITIVE CLIP:\")\n",
    "    if loaded_clip_pos_embedding is not None:\n",
    "        print(f\"  Shape: {loaded_clip_pos_embedding.shape}\")\n",
    "        print(f\"  Prompt: '{loaded_clip_pos_prompt}'\")\n",
    "        \n",
    "        # Use last token embedding as pooled embedding (EOS token)\n",
    "        clip_pos_pooled = torch.from_numpy(\n",
    "            loaded_clip_pos_embedding[-1:].astype(np.float32)\n",
    "        ).to(device=device, dtype=torch.bfloat16)\n",
    "    else:\n",
    "        print(\"  Generating from T5 prompt using CLIP model...\")\n",
    "        # Generate default CLIP embedding from prompt\n",
    "        with torch.no_grad():\n",
    "            _, clip_pos_pooled, _ = sd_pipe.encode_prompt(\n",
    "                prompt=loaded_t5_pos_prompt,\n",
    "                prompt_2=None,\n",
    "                prompt_3=None,\n",
    "                device=device,\n",
    "                num_images_per_prompt=1,\n",
    "            )\n",
    "    \n",
    "    # Process NEGATIVE CLIP embedding\n",
    "    if loaded_clip_neg_embedding is not None:\n",
    "        print(\"\\nNEGATIVE CLIP:\")\n",
    "        print(f\"  Shape: {loaded_clip_neg_embedding.shape}\")\n",
    "        print(f\"  Prompt: '{loaded_clip_neg_prompt}'\")\n",
    "        \n",
    "        clip_neg_pooled = torch.from_numpy(\n",
    "            loaded_clip_neg_embedding[-1:].astype(np.float32)\n",
    "        ).to(device=device, dtype=torch.bfloat16)\n",
    "    else:\n",
    "        print(\"\\nNEGATIVE CLIP: Using default (empty)\")\n",
    "        clip_neg_pooled = None\n",
    "    \n",
    "    # Construct filename\n",
    "    t5_pos_tokens, t5_pos_manip = parse_embedding_filename(t5_pos_dropdown.value)\n",
    "    t5_neg_tokens, t5_neg_manip = parse_embedding_filename(t5_neg_dropdown.value)\n",
    "    clip_pos_tokens, clip_pos_manip = parse_embedding_filename(clip_pos_dropdown.value)\n",
    "    clip_neg_tokens, clip_neg_manip = parse_embedding_filename(clip_neg_dropdown.value)\n",
    "    \n",
    "    # Build filename: t5pos_t5neg_clippos_clipneg_cfg{guidance}.png\n",
    "    filename_parts = []\n",
    "    filename_parts.append(f\"t5pos_{t5_pos_tokens}{('_'+t5_pos_manip) if t5_pos_manip else ''}\")\n",
    "    if t5_neg_tokens != 'none':\n",
    "        filename_parts.append(f\"t5neg_{t5_neg_tokens}{('_'+t5_neg_manip) if t5_neg_manip else ''}\")\n",
    "    filename_parts.append(f\"clippos_{clip_pos_tokens}{('_'+clip_pos_manip) if clip_pos_manip else ''}\")\n",
    "    if clip_neg_tokens != 'none':\n",
    "        filename_parts.append(f\"clipneg_{clip_neg_tokens}{('_'+clip_neg_manip) if clip_neg_manip else ''}\")\n",
    "    filename_parts.append(f\"cfg{guidance_scale:.1f}\")\n",
    "    \n",
    "    filename = '_'.join(filename_parts) + '.png'\n",
    "    output_filepath = OUTPUT_IMAGES_DIR / filename\n",
    "    \n",
    "    # Generate image\n",
    "    try:\n",
    "        print(f\"\\nRunning SD 3.5 diffusion (28 steps)...\")\n",
    "        image = sd_pipe(\n",
    "            prompt_embeds=t5_pos_tensor,\n",
    "            negative_prompt_embeds=t5_neg_tensor,\n",
    "            pooled_prompt_embeds=clip_pos_pooled,\n",
    "            negative_pooled_prompt_embeds=clip_neg_pooled,\n",
    "            num_inference_steps=28,\n",
    "            guidance_scale=guidance_scale,\n",
    "            height=1024,\n",
    "            width=1024,\n",
    "            generator=torch.manual_seed(seed)\n",
    "        ).images[0]\n",
    "        \n",
    "        image.save(output_filepath)\n",
    "        print(f\"\\n✓ Image generated and saved!\")\n",
    "        print(f\"  Path: {output_filepath}\")\n",
    "        print(f\"  Filename: {filename}\")\n",
    "        \n",
    "        return image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating image: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Generation controls\n",
    "seed_input = widgets.IntText(\n",
    "    value=42,\n",
    "    description='Seed:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "guidance_input = widgets.FloatSlider(\n",
    "    value=7.0,\n",
    "    min=0.0,\n",
    "    max=20.0,\n",
    "    step=0.5,\n",
    "    description='Guidance Scale:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    readout_format='.1f'\n",
    ")\n",
    "\n",
    "generate_button = widgets.Button(\n",
    "    description='Generate Image',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='300px', height='50px')\n",
    ")\n",
    "\n",
    "generation_output = widgets.Output()\n",
    "\n",
    "def on_generate_click(b):\n",
    "    with generation_output:\n",
    "        generation_output.clear_output(wait=True)\n",
    "        \n",
    "        image = generate_from_loaded_embeddings(\n",
    "            seed=seed_input.value,\n",
    "            guidance_scale=guidance_input.value\n",
    "        )\n",
    "        \n",
    "        if image:\n",
    "            display(image)\n",
    "\n",
    "generate_button.on_click(on_generate_click)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    widgets.HTML(\"<h3>3. Generate Image</h3>\"),\n",
    "    widgets.HTML(\"<p><b>Guidance Scale:</b> Higher values (7-15) follow the positive prompt more closely and avoid the negative prompt. Lower values (1-5) give more creative freedom.</p>\"),\n",
    "    seed_input,\n",
    "    guidance_input,\n",
    "    generate_button\n",
    "]), generation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Differences from FLUX:\n",
    "\n",
    "1. **Negative Embeddings**: SD 3.5 supports negative T5 and CLIP embeddings to steer generation away from unwanted concepts\n",
    "2. **Guidance Scale**: Control how strongly the model follows positive vs negative prompts (FLUX.1-schnell doesn't use guidance)\n",
    "3. **More Inference Steps**: SD 3.5 uses 28 steps by default vs FLUX's 4 steps\n",
    "4. **Different Architecture**: SD 3.5 uses traditional diffusion with CFG, FLUX uses rectified flow\n",
    "\n",
    "### Workflow:\n",
    "\n",
    "1. Load **positive** T5 embedding (required)\n",
    "2. Load **negative** T5 embedding (optional)\n",
    "3. Load **positive** CLIP embedding (required or auto-generated)\n",
    "4. Load **negative** CLIP embedding (optional)\n",
    "5. Adjust **guidance scale** (7.0 is default, 10-15 for stronger adherence)\n",
    "6. Set **seed** for reproducibility\n",
    "7. Generate and compare results!\n",
    "\n",
    "### Experiment Ideas:\n",
    "\n",
    "- Use manipulated embeddings (zeroed, scaled, inverted) as negative prompts\n",
    "- Compare same embeddings with different guidance scales\n",
    "- Mix and match: positive normal + negative zeroed\n",
    "- Compare SD 3.5 vs FLUX results side-by-side"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
